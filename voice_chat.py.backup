"""
çº¿ä¸‹è¯­éŸ³å¯¹è¯ç³»ç»Ÿ
ä½¿ç”¨USBéº¦å…‹é£å½•éŸ³ï¼Œé€šè¿‡è“ç‰™éŸ³ç®±æ’­æ”¾å›å¤
"""

import os
import sys
import logging
from pathlib import Path
import time
import subprocess
import tempfile
import threading
import warnings
from contextlib import contextmanager
from queue import Queue, Empty

# æŠ‘åˆ¶ALSAè­¦å‘Šä¿¡æ¯
os.environ['PYAUDIO_ALSA_ERRORS'] = '0'
warnings.filterwarnings('ignore', category=DeprecationWarning)

# é‡å®šå‘stderrä»¥æŠ‘åˆ¶ALSAé”™è¯¯ä¿¡æ¯
@contextmanager
def suppress_stderr():
    """ä¸´æ—¶æŠ‘åˆ¶stderrè¾“å‡ºï¼ˆç”¨äºæŠ‘åˆ¶ALSAé”™è¯¯ï¼‰"""
    devnull = os.open(os.devnull, os.O_WRONLY)
    old_stderr = os.dup(2)
    sys.stderr.flush()
    os.dup2(devnull, 2)
    os.close(devnull)
    try:
        yield
    finally:
        os.dup2(old_stderr, 2)
        os.close(old_stderr)

# åœ¨å¯¼å…¥pyaudioæ—¶æŠ‘åˆ¶ALSAé”™è¯¯
with suppress_stderr():
    import pyaudio

import wave
import numpy as np
import requests
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
from scipy import signal

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))
from config_loader import get_config

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("VoiceChat")

# åˆ›å»ºFastAPIåº”ç”¨ç”¨äºAPIæ¥å£
app = FastAPI(title="Voice Chat API")

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class AudioPlaybackQueue:
    """
    éŸ³é¢‘æ’­æ”¾é˜Ÿåˆ—ç®¡ç†å™¨
    å®ç°ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼ï¼Œæ”¯æŒTTSå¼‚æ­¥ç”Ÿæˆå’Œæ’­æ”¾
    """

    def __init__(self, voice_assistant):
        self.queue = Queue()
        self.voice_assistant = voice_assistant
        self.is_playing = False
        self.stop_flag = False
        self.playback_thread = None
        self.output_device = None

    def start(self, output_device=None):
        """å¯åŠ¨æ’­æ”¾çº¿ç¨‹"""
        self.output_device = output_device
        self.stop_flag = False
        self.playback_thread = threading.Thread(target=self._playback_worker, daemon=True)
        self.playback_thread.start()
        logger.info("ğŸµ éŸ³é¢‘æ’­æ”¾é˜Ÿåˆ—å·²å¯åŠ¨")

    def stop(self):
        """åœæ­¢æ’­æ”¾çº¿ç¨‹"""
        self.stop_flag = True
        # æ¸…ç©ºé˜Ÿåˆ—
        while not self.queue.empty():
            try:
                audio_file, _ = self.queue.get_nowait()
                # åˆ é™¤æœªæ’­æ”¾çš„éŸ³é¢‘æ–‡ä»¶
                if audio_file and os.path.exists(audio_file):
                    os.unlink(audio_file)
            except Empty:
                break

        if self.playback_thread:
            self.playback_thread.join(timeout=2)
        logger.info("ğŸ›‘ éŸ³é¢‘æ’­æ”¾é˜Ÿåˆ—å·²åœæ­¢")

    def add(self, audio_file, text=""):
        """æ·»åŠ éŸ³é¢‘åˆ°æ’­æ”¾é˜Ÿåˆ—"""
        if audio_file:
            self.queue.put((audio_file, text))
            logger.debug(f"ğŸ“¥ éŸ³é¢‘å·²åŠ å…¥é˜Ÿåˆ—ï¼Œå½“å‰é˜Ÿåˆ—é•¿åº¦: {self.queue.qsize()}")

    def _playback_worker(self):
        """æ’­æ”¾å·¥ä½œçº¿ç¨‹"""
        logger.info("ğŸ§ æ’­æ”¾å·¥ä½œçº¿ç¨‹å·²å¯åŠ¨")

        while not self.stop_flag:
            try:
                # ç­‰å¾…é˜Ÿåˆ—ä¸­çš„éŸ³é¢‘ï¼Œè¶…æ—¶1ç§’
                audio_file, text = self.queue.get(timeout=1)

                if audio_file and os.path.exists(audio_file):
                    self.is_playing = True
                    if text:
                        logger.info(f"ğŸ”Š æ­£åœ¨æ’­æ”¾: {text[:30]}...")

                    # è°ƒç”¨è¯­éŸ³åŠ©æ‰‹çš„æ’­æ”¾æ–¹æ³•
                    # æ’­æ”¾æ—¶ä¼šæ£€æŸ¥interrupt_flag
                    self.voice_assistant.play_audio(audio_file, self.output_device)
                    self.is_playing = False

                    # æ£€æŸ¥æ˜¯å¦è¢«æ‰“æ–­
                    if self.voice_assistant.interrupt_flag:
                        logger.info("â¹ï¸ æ£€æµ‹åˆ°æ‰“æ–­æ ‡å¿—ï¼Œæ¸…ç©ºæ’­æ”¾é˜Ÿåˆ—")
                        # æ¸…ç©ºå‰©ä½™é˜Ÿåˆ—
                        while not self.queue.empty():
                            try:
                                remaining_file, _ = self.queue.get_nowait()
                                if remaining_file and os.path.exists(remaining_file):
                                    os.unlink(remaining_file)
                                self.queue.task_done()
                            except Empty:
                                break
                        # æ ‡è®°å½“å‰ä»»åŠ¡å®Œæˆ
                        self.queue.task_done()
                        break

                    # æ ‡è®°ä»»åŠ¡å®Œæˆ
                    self.queue.task_done()
                else:
                    logger.warning(f"âš ï¸ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ•ˆ: {audio_file}")

            except Empty:
                # é˜Ÿåˆ—ä¸ºç©ºï¼Œç»§ç»­ç­‰å¾…
                continue
            except Exception as e:
                logger.error(f"âŒ æ’­æ”¾éŸ³é¢‘æ—¶å‡ºé”™: {e}")
                import traceback
                logger.error(traceback.format_exc())
                self.is_playing = False

        logger.info("ğŸ›‘ æ’­æ”¾å·¥ä½œçº¿ç¨‹å·²é€€å‡º")

    def wait_until_done(self):
        """ç­‰å¾…æ‰€æœ‰éŸ³é¢‘æ’­æ”¾å®Œæˆ"""
        self.queue.join()
        # ç­‰å¾…å½“å‰æ­£åœ¨æ’­æ”¾çš„éŸ³é¢‘å®Œæˆ
        while self.is_playing:
            time.sleep(0.1)

    def get_queue_size(self):
        """è·å–é˜Ÿåˆ—é•¿åº¦"""
        return self.queue.qsize()


class VoiceAssistant:
    """è¯­éŸ³åŠ©æ‰‹æ ¸å¿ƒç±»"""

    def __init__(self):
        # å¯¹è¯å†å²æ ¼å¼: [[ç”¨æˆ·é—®é¢˜1, AIå›ç­”1], [ç”¨æˆ·é—®é¢˜2, AIå›ç­”2]]
        self.conversation_history = []
        self.ports = get_config('services')

        # ä»é…ç½®åŠ è½½å‚æ•°
        voice_config = get_config('voice_chat')

        # éŸ³é¢‘å‚æ•°
        self.CHUNK = 1024
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.RATE = 16000

        # VADå‚æ•°
        self.SILENCE_THRESHOLD = voice_config.get('silence_threshold', 500)
        self.SILENCE_DURATION = voice_config.get('silence_duration', 1.5)
        self.MIN_AUDIO_LENGTH = voice_config.get('min_audio_length', 0.5)

        # éŸ³é‡å‚æ•°
        self.OUTPUT_VOLUME = voice_config.get('output_volume', 100)

        # å”¤é†’è¯å‚æ•°
        self.WAKE_WORDS = voice_config.get('wake_words', ["å°åŠ©æ‰‹", "ä½ å¥½åŠ©æ‰‹", "å˜¿åŠ©æ‰‹", "å°çˆ±"])
        self.WAKE_MODE = voice_config.get('wake_mode', True)
        self.WAKE_REPLY = voice_config.get('wake_reply', "ä½ å¥½ï¼Œæˆ‘åœ¨")  # å”¤é†’ç¡®è®¤è¯­éŸ³

        # æ‰“æ–­è¯å‚æ•°
        self.INTERRUPT_MODE = voice_config.get('interrupt_mode', True)
        self.INTERRUPT_WORDS = voice_config.get('interrupt_words', ["åœæ­¢", "æš‚åœ", "åˆ«è¯´äº†"])
        self.INTERRUPT_REPLY = voice_config.get('interrupt_reply', "å¥½çš„ï¼Œå·²åœæ­¢")  # æ‰“æ–­ç¡®è®¤è¯­éŸ³
        self.interrupt_flag = False  # æ‰“æ–­æ ‡å¿—
        self.interrupt_monitor_thread = None  # æ‰“æ–­ç›‘å¬çº¿ç¨‹

        # æ€è€ƒå›å¤å‚æ•°
        self.THINKING_REPLY = voice_config.get('thinking_reply', "å¥½ï¼Œæˆ‘çŸ¥é“äº†ï¼Œç­‰æˆ‘æƒ³ä¸€ä¸‹")  # å¼€å§‹æ€è€ƒç¡®è®¤è¯­éŸ³

        # è¿ç»­å¯¹è¯å‚æ•°
        self.CONTINUE_DIALOGUE_TIMEOUT = voice_config.get('continue_dialogue_timeout', 5.0)  # è¿ç»­å¯¹è¯è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

        # éŸ³é¢‘ç¼“å­˜ç›®å½•
        self.cache_dir = Path(__file__).parent / "audio_cache"
        self.cache_dir.mkdir(exist_ok=True)

        # éŸ³é¢‘ç¼“å­˜ï¼ˆé¿å…é‡å¤ç”Ÿæˆç›¸åŒçš„å›å¤éŸ³é¢‘ï¼‰
        self.wake_reply_audio_cache = None  # å”¤é†’å›å¤éŸ³é¢‘ç¼“å­˜
        self.interrupt_reply_audio_cache = None  # æ‰“æ–­å›å¤éŸ³é¢‘ç¼“å­˜
        self.thinking_reply_audio_cache = None  # æ€è€ƒå›å¤éŸ³é¢‘ç¼“å­˜

        # æƒ…ç»ªç›‘æ§ç›¸å…³
        emotion_config = get_config('emotion_context', {})
        self.EMOTION_ENABLE = emotion_config.get('enable', False)
        self.emotion_service_url = emotion_config.get('service_url', 'http://localhost:5005')
        self.current_emotion = None
        self.emotion_context = ""

        # é•¿æ—¶è®°å¿†ç›¸å…³
        memory_config = get_config('memory_service', {})
        self.MEMORY_ENABLE = memory_config.get('enable', False)
        self.memory_service_url = memory_config.get('service_url', 'http://localhost:5006')
        self.auto_extract = memory_config.get('auto_extract', True)
        self.memory_client = None

        # åˆå§‹åŒ–è®°å¿†å®¢æˆ·ç«¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.MEMORY_ENABLE:
            try:
                from memory_service.memory_client import MemoryClient
                self.memory_client = MemoryClient(self.memory_service_url)
                if self.memory_client.check_service():
                    logger.info("âœ… é•¿æ—¶è®°å¿†æœåŠ¡è¿æ¥æˆåŠŸ")
                else:
                    logger.warning("âš ï¸ é•¿æ—¶è®°å¿†æœåŠ¡æœªè¿è¡Œ")
                    self.MEMORY_ENABLE = False
            except Exception as e:
                logger.error(f"åˆå§‹åŒ–è®°å¿†å®¢æˆ·ç«¯å¤±è´¥: {e}")
                self.MEMORY_ENABLE = False

        # åŠ è½½ç¼“å­˜çš„éŸ³é¢‘
        self._load_cached_audio()

        # åˆå§‹åŒ–PyAudioï¼ˆæŠ‘åˆ¶ALSAé”™è¯¯ï¼‰
        with suppress_stderr():
            self.audio = pyaudio.PyAudio()

        # å­˜å‚¨è®¾å¤‡é…ç½®
        self.input_device = voice_config.get('input_device')
        self.output_device = voice_config.get('output_device')

        # æ£€æµ‹å¹¶è°ƒæ•´è¾“å…¥è®¾å¤‡çš„é‡‡æ ·ç‡
        if self.input_device is not None:
            try:
                device_info = self.audio.get_device_info_by_index(self.input_device)
                device_rate = int(device_info['defaultSampleRate'])

                # å°è¯•æµ‹è¯•è®¾å¤‡æ˜¯å¦æ”¯æŒ16000Hz
                try:
                    with suppress_stderr():
                        test_stream = self.audio.open(
                            format=self.FORMAT,
                            channels=self.CHANNELS,
                            rate=16000,
                            input=True,
                            input_device_index=self.input_device,
                            frames_per_buffer=self.CHUNK,
                            start=False
                        )
                        test_stream.close()
                    logger.info(f"è®¾å¤‡æ”¯æŒ16000Hzé‡‡æ ·ç‡")
                except:
                    # è®¾å¤‡ä¸æ”¯æŒ16000Hz,ä½¿ç”¨è®¾å¤‡é»˜è®¤é‡‡æ ·ç‡
                    logger.warning(f"è®¾å¤‡ä¸æ”¯æŒ16000Hzé‡‡æ ·ç‡,å°†ä½¿ç”¨è®¾å¤‡é»˜è®¤é‡‡æ ·ç‡: {device_rate}Hz")
                    self.RATE = device_rate
            except Exception as e:
                logger.warning(f"æ— æ³•è·å–è®¾å¤‡ä¿¡æ¯: {e},ä½¿ç”¨é»˜è®¤é‡‡æ ·ç‡")

        logger.info(f"ä½¿ç”¨é‡‡æ ·ç‡: {self.RATE}Hz")
        logger.info(f"è¾“å‡ºéŸ³é‡: {self.OUTPUT_VOLUME}%")
        logger.info("è¯­éŸ³åŠ©æ‰‹åˆå§‹åŒ–å®Œæˆ")
        if self.WAKE_MODE:
            logger.info(f"å”¤é†’è¯æ¨¡å¼å·²å¯ç”¨ï¼Œæ”¯æŒçš„å”¤é†’è¯: {', '.join(self.WAKE_WORDS)}")

    def _get_cache_filename(self, text, cache_type):
        """
        ç”Ÿæˆç¼“å­˜æ–‡ä»¶åï¼ˆåŸºäºæ–‡æœ¬å†…å®¹çš„å“ˆå¸Œï¼‰

        Args:
            text: æ–‡æœ¬å†…å®¹
            cache_type: ç¼“å­˜ç±»å‹ ('wake' æˆ– 'interrupt')

        Returns:
            str: ç¼“å­˜æ–‡ä»¶è·¯å¾„
        """
        import hashlib
        text_hash = hashlib.md5(text.encode('utf-8')).hexdigest()[:16]
        return self.cache_dir / f"{cache_type}_reply_{text_hash}.pcm"

    def _load_cached_audio(self):
        """åŠ è½½ç¼“å­˜çš„éŸ³é¢‘æ–‡ä»¶"""
        # åŠ è½½å”¤é†’å›å¤éŸ³é¢‘ï¼ˆä½¿ç”¨å¸¦"ä¸€"å‰ç¼€çš„æ–‡æœ¬ï¼‰
        wake_text_with_prefix = "ä¸€" + self.WAKE_REPLY
        wake_cache_file = self._get_cache_filename(wake_text_with_prefix, 'wake')
        if wake_cache_file.exists():
            self.wake_reply_audio_cache = str(wake_cache_file)
            logger.info(f"âœ… åŠ è½½å”¤é†’å›å¤éŸ³é¢‘ç¼“å­˜: {self.WAKE_REPLY}")
        else:
            logger.info(f"ğŸ’¾ å”¤é†’å›å¤éŸ³é¢‘ç¼“å­˜ä¸å­˜åœ¨ï¼Œå°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶ç”Ÿæˆ")

        # åŠ è½½æ‰“æ–­å›å¤éŸ³é¢‘ï¼ˆä½¿ç”¨å¸¦"ä¸€"å‰ç¼€çš„æ–‡æœ¬ï¼‰
        interrupt_text_with_prefix = "ä¸€" + self.INTERRUPT_REPLY
        interrupt_cache_file = self._get_cache_filename(interrupt_text_with_prefix, 'interrupt')
        if interrupt_cache_file.exists():
            self.interrupt_reply_audio_cache = str(interrupt_cache_file)
            logger.info(f"âœ… åŠ è½½æ‰“æ–­å›å¤éŸ³é¢‘ç¼“å­˜: {self.INTERRUPT_REPLY}")
        else:
            logger.info(f"ğŸ’¾ æ‰“æ–­å›å¤éŸ³é¢‘ç¼“å­˜ä¸å­˜åœ¨ï¼Œå°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶ç”Ÿæˆ")

        # åŠ è½½æ€è€ƒå›å¤éŸ³é¢‘ï¼ˆä½¿ç”¨å¸¦"ä¸€"å‰ç¼€çš„æ–‡æœ¬ï¼‰
        thinking_text_with_prefix = "ä¸€" + self.THINKING_REPLY
        thinking_cache_file = self._get_cache_filename(thinking_text_with_prefix, 'thinking')
        if thinking_cache_file.exists():
            self.thinking_reply_audio_cache = str(thinking_cache_file)
            logger.info(f"âœ… åŠ è½½æ€è€ƒå›å¤éŸ³é¢‘ç¼“å­˜: {self.THINKING_REPLY}")
        else:
            logger.info(f"ğŸ’¾ æ€è€ƒå›å¤éŸ³é¢‘ç¼“å­˜ä¸å­˜åœ¨ï¼Œå°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶ç”Ÿæˆ")

    def get_emotion_context(self):
        """è·å–å½“å‰æƒ…ç»ªä¸Šä¸‹æ–‡"""
        if not self.EMOTION_ENABLE:
            return ""

        try:
            # è¯·æ±‚æƒ…ç»ªç»Ÿè®¡æ¥å£
            response = requests.get(
                f"{self.emotion_service_url}/emotion/stats",
                timeout=2
            )

            if response.status_code == 200:
                data = response.json()

                if data.get("status") == "success":
                    dominant_emotion = data.get("dominant_emotion", "neutral")
                    confidence = data.get("confidence", 0)

                    # æ›´æ–°å½“å‰æƒ…ç»ª
                    self.current_emotion = dominant_emotion

                    # ç”Ÿæˆæƒ…ç»ªä¸Šä¸‹æ–‡æè¿°
                    emotion_descriptions = {
                        "happy": "ç”¨æˆ·å½“å‰çœ‹èµ·æ¥å¾ˆå¼€å¿ƒ",
                        "sad": "ç”¨æˆ·å½“å‰å¯èƒ½æƒ…ç»ªä½è½",
                        "angry": "ç”¨æˆ·å½“å‰çœ‹èµ·æ¥æœ‰äº›ç”Ÿæ°”",
                        "surprise": "ç”¨æˆ·å½“å‰çœ‹èµ·æ¥å¾ˆæƒŠè®¶",
                        "neutral": "ç”¨æˆ·å½“å‰æƒ…ç»ªå¹³é™",
                        "fear": "ç”¨æˆ·å½“å‰çœ‹èµ·æ¥æœ‰äº›ç´§å¼ ",
                        "disgust": "ç”¨æˆ·å½“å‰çœ‹èµ·æ¥æœ‰äº›ä¸æ‚¦"
                    }

                    base_desc = emotion_descriptions.get(dominant_emotion, "ç”¨æˆ·å½“å‰æƒ…ç»ªå¹³é™")

                    # æ ¹æ®ç½®ä¿¡åº¦æ·»åŠ æè¿°
                    if confidence > 0.8:
                        return f"{base_desc}ï¼ˆéå¸¸ç¡®å®šï¼‰"
                    elif confidence > 0.6:
                        return f"{base_desc}ï¼ˆæ¯”è¾ƒç¡®å®šï¼‰"
                    else:
                        return f"{base_desc}ï¼ˆä¸å¤ªç¡®å®šï¼‰"
                else:
                    logger.debug(f"æƒ…ç»ªæœåŠ¡è¿”å›é”™è¯¯: {data.get('message', 'Unknown error')}")
            else:
                logger.debug(f"æƒ…ç»ªæœåŠ¡è¯·æ±‚å¤±è´¥: {response.status_code}")

        except requests.exceptions.RequestException as e:
            logger.debug(f"æ— æ³•è¿æ¥åˆ°æƒ…ç»ªæœåŠ¡: {e}")
        except Exception as e:
            logger.error(f"è·å–æƒ…ç»ªä¸Šä¸‹æ–‡æ—¶å‡ºé”™: {e}")

        return ""

    def update_emotion_context(self):
        """æ›´æ–°æƒ…ç»ªä¸Šä¸‹æ–‡"""
        self.emotion_context = self.get_emotion_context()
        if self.emotion_context:
            logger.info(f"ğŸ’­ æƒ…ç»ªä¸Šä¸‹æ–‡: {self.emotion_context}")

    def _save_audio_cache(self, text, cache_type, audio_file):
        """
        ä¿å­˜éŸ³é¢‘åˆ°ç¼“å­˜

        Args:
            text: æ–‡æœ¬å†…å®¹
            cache_type: ç¼“å­˜ç±»å‹ ('wake' æˆ– 'interrupt')
            audio_file: ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶è·¯å¾„

        Returns:
            str: ç¼“å­˜æ–‡ä»¶è·¯å¾„
        """
        try:
            cache_file = self._get_cache_filename(text, cache_type)

            # å¤åˆ¶éŸ³é¢‘æ–‡ä»¶åˆ°ç¼“å­˜ç›®å½•
            import shutil
            shutil.copy2(audio_file, cache_file)

            logger.info(f"ğŸ’¾ å·²ä¿å­˜{cache_type}å›å¤éŸ³é¢‘ç¼“å­˜: {text} -> {cache_file.name}")
            return str(cache_file)
        except Exception as e:
            logger.error(f"ä¿å­˜éŸ³é¢‘ç¼“å­˜å¤±è´¥: {e}")
            return None

    def _clear_audio_cache(self):
        """æ¸…é™¤æ‰€æœ‰éŸ³é¢‘ç¼“å­˜"""
        try:
            import shutil
            if self.cache_dir.exists():
                shutil.rmtree(self.cache_dir)
                self.cache_dir.mkdir(exist_ok=True)
                logger.info("ğŸ—‘ï¸ å·²æ¸…é™¤æ‰€æœ‰éŸ³é¢‘ç¼“å­˜")

            # é‡ç½®ç¼“å­˜å˜é‡
            self.wake_reply_audio_cache = None
            self.interrupt_reply_audio_cache = None
        except Exception as e:
            logger.error(f"æ¸…é™¤éŸ³é¢‘ç¼“å­˜å¤±è´¥: {e}")

    def list_audio_devices(self):
        """åˆ—å‡ºæ‰€æœ‰éŸ³é¢‘è®¾å¤‡"""
        logger.info("=" * 60)
        logger.info("å¯ç”¨éŸ³é¢‘è®¾å¤‡åˆ—è¡¨:")
        logger.info("=" * 60)

        for i in range(self.audio.get_device_count()):
            info = self.audio.get_device_info_by_index(i)
            logger.info(f"è®¾å¤‡ {i}: {info['name']}")
            logger.info(f"  è¾“å…¥é€šé“: {info['maxInputChannels']}")
            logger.info(f"  è¾“å‡ºé€šé“: {info['maxOutputChannels']}")
            logger.info(f"  é‡‡æ ·ç‡: {info['defaultSampleRate']}")
            logger.info("-" * 60)

    def reload_config(self):
        """
        é‡æ–°åŠ è½½é…ç½®å‚æ•°ï¼ˆçƒ­é‡è½½ï¼‰
        æ³¨æ„ï¼šæŸäº›é…ç½®ï¼ˆå¦‚éŸ³é¢‘è®¾å¤‡ï¼‰çš„æ›´æ”¹å¯èƒ½éœ€è¦é‡å¯è¯­éŸ³å¯¹è¯æ‰èƒ½ç”Ÿæ•ˆ
        """
        try:
            from config_loader import reload_config as reload_config_file
            reload_config_file()  # å…ˆæ›´æ–° ConfigLoader çš„ config

            voice_config = get_config('voice_chat')
            self.ports = get_config('services')

            # æ›´æ–° VAD å‚æ•°
            old_threshold = self.SILENCE_THRESHOLD
            self.SILENCE_THRESHOLD = voice_config.get('silence_threshold', 500)
            self.SILENCE_DURATION = voice_config.get('silence_duration', 1.5)
            self.MIN_AUDIO_LENGTH = voice_config.get('min_audio_length', 0.5)

            if old_threshold != self.SILENCE_THRESHOLD:
                logger.info(f"ğŸ”„ é™éŸ³é˜ˆå€¼å·²æ›´æ–°: {old_threshold} â†’ {self.SILENCE_THRESHOLD}")

            # æ›´æ–°éŸ³é‡å‚æ•°
            old_volume = self.OUTPUT_VOLUME
            self.OUTPUT_VOLUME = voice_config.get('output_volume', 100)
            if old_volume != self.OUTPUT_VOLUME:
                logger.info(f"ğŸ”„ è¾“å‡ºéŸ³é‡å·²æ›´æ–°: {old_volume}% â†’ {self.OUTPUT_VOLUME}%")

            # æ›´æ–°å”¤é†’è¯å‚æ•°
            old_wake_mode = self.WAKE_MODE
            old_wake_words = self.WAKE_WORDS
            old_wake_reply = self.WAKE_REPLY
            self.WAKE_WORDS = voice_config.get('wake_words', ["å°åŠ©æ‰‹", "ä½ å¥½åŠ©æ‰‹", "å˜¿åŠ©æ‰‹", "å°çˆ±"])
            self.WAKE_MODE = voice_config.get('wake_mode', True)
            self.WAKE_REPLY = voice_config.get('wake_reply', "ä½ å¥½ï¼Œæˆ‘åœ¨")

            if old_wake_mode != self.WAKE_MODE:
                logger.info(f"ğŸ”„ å”¤é†’è¯æ¨¡å¼å·²{'å¯ç”¨' if self.WAKE_MODE else 'ç¦ç”¨'}")
            if old_wake_words != self.WAKE_WORDS:
                logger.info(f"ğŸ”„ å”¤é†’è¯å·²æ›´æ–°: {old_wake_words} â†’ {self.WAKE_WORDS}")
            if old_wake_reply != self.WAKE_REPLY:
                logger.info(f"ğŸ”„ å”¤é†’å›å¤å·²æ›´æ–°: {old_wake_reply} â†’ {self.WAKE_REPLY}")
                # æ¸…é™¤æ—§çš„ç¼“å­˜
                self.wake_reply_audio_cache = None
                logger.info("ğŸ—‘ï¸ å·²æ¸…é™¤å”¤é†’å›å¤éŸ³é¢‘ç¼“å­˜ï¼Œå°†åœ¨ä¸‹æ¬¡ä½¿ç”¨æ—¶é‡æ–°ç”Ÿæˆ")

            # æ›´æ–°æ‰“æ–­è¯å‚æ•°
            old_interrupt_mode = self.INTERRUPT_MODE
            old_interrupt_words = self.INTERRUPT_WORDS
            old_interrupt_reply = self.INTERRUPT_REPLY
            self.INTERRUPT_MODE = voice_config.get('interrupt_mode', True)
            self.INTERRUPT_WORDS = voice_config.get('interrupt_words', ["åœæ­¢", "æš‚åœ", "åˆ«è¯´äº†"])
            self.INTERRUPT_REPLY = voice_config.get('interrupt_reply', "å¥½çš„ï¼Œå·²åœæ­¢")

            if old_interrupt_mode != self.INTERRUPT_MODE:
                logger.info(f"ğŸ”„ æ‰“æ–­æ¨¡å¼å·²{'å¯ç”¨' if self.INTERRUPT_MODE else 'ç¦ç”¨'}")
            if old_interrupt_words != self.INTERRUPT_WORDS:
                logger.info(f"ğŸ”„ æ‰“æ–­è¯å·²æ›´æ–°: {old_interrupt_words} â†’ {self.INTERRUPT_WORDS}")
            if old_interrupt_reply != self.INTERRUPT_REPLY:
                logger.info(f"ğŸ”„ æ‰“æ–­å›å¤å·²æ›´æ–°: {old_interrupt_reply} â†’ {self.INTERRUPT_REPLY}")
                # æ¸…é™¤æ—§çš„ç¼“å­˜
                self.interrupt_reply_audio_cache = None
                logger.info("ğŸ—‘ï¸ å·²æ¸…é™¤æ‰“æ–­å›å¤éŸ³é¢‘ç¼“å­˜ï¼Œå°†åœ¨ä¸‹æ¬¡ä½¿ç”¨æ—¶é‡æ–°ç”Ÿæˆ")

            # æ›´æ–°æ€è€ƒå›å¤å‚æ•°
            old_thinking_reply = self.THINKING_REPLY
            self.THINKING_REPLY = voice_config.get('thinking_reply', "å¥½ï¼Œæˆ‘çŸ¥é“äº†ï¼Œç­‰æˆ‘æƒ³ä¸€ä¸‹")

            if old_thinking_reply != self.THINKING_REPLY:
                logger.info(f"ğŸ”„ æ€è€ƒå›å¤å·²æ›´æ–°: {old_thinking_reply} â†’ {self.THINKING_REPLY}")
                # æ¸…é™¤æ—§çš„ç¼“å­˜
                self.thinking_reply_audio_cache = None
                logger.info("ğŸ—‘ï¸ å·²æ¸…é™¤æ€è€ƒå›å¤éŸ³é¢‘ç¼“å­˜ï¼Œå°†åœ¨ä¸‹æ¬¡ä½¿ç”¨æ—¶é‡æ–°ç”Ÿæˆ")

            # æ›´æ–°è®¾å¤‡é…ç½®ï¼ˆæ³¨æ„ï¼šè®¾å¤‡åˆ‡æ¢éœ€è¦é‡å¯è¯­éŸ³å¯¹è¯æ‰èƒ½ç”Ÿæ•ˆï¼‰
            old_input = self.input_device
            old_output = self.output_device
            self.input_device = voice_config.get('input_device')
            self.output_device = voice_config.get('output_device')

            if old_input != self.input_device or old_output != self.output_device:
                logger.warning("âš ï¸ éŸ³é¢‘è®¾å¤‡é…ç½®å·²æ›´æ–°ï¼Œä½†éœ€è¦é‡å¯è¯­éŸ³å¯¹è¯æ‰èƒ½ç”Ÿæ•ˆ")

            logger.info("âœ… VoiceAssistant é…ç½®å·²é‡æ–°åŠ è½½")

            return {
                "success": True,
                "message": "é…ç½®å·²é‡æ–°åŠ è½½",
                "changes": {
                    "silence_threshold": self.SILENCE_THRESHOLD,
                    "output_volume": self.OUTPUT_VOLUME,
                    "wake_mode": self.WAKE_MODE,
                    "wake_words": self.WAKE_WORDS,
                    "wake_reply": self.WAKE_REPLY,
                    "interrupt_mode": self.INTERRUPT_MODE,
                    "interrupt_words": self.INTERRUPT_WORDS,
                    "interrupt_reply": self.INTERRUPT_REPLY,
                    "thinking_reply": self.THINKING_REPLY
                }
            }

        except Exception as e:
            logger.error(f"âŒ é…ç½®é‡æ–°åŠ è½½å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return {
                "success": False,
                "error": str(e)
            }

    def get_default_input_device(self):
        """è·å–é»˜è®¤è¾“å…¥è®¾å¤‡"""
        try:
            default_input = self.audio.get_default_input_device_info()
            logger.info(f"é»˜è®¤è¾“å…¥è®¾å¤‡: {default_input['name']}")
            return default_input['index']
        except Exception as e:
            logger.error(f"è·å–é»˜è®¤è¾“å…¥è®¾å¤‡å¤±è´¥: {e}")
            return None

    def get_default_output_device(self):
        """è·å–é»˜è®¤è¾“å‡ºè®¾å¤‡"""
        try:
            default_output = self.audio.get_default_output_device_info()
            logger.info(f"é»˜è®¤è¾“å‡ºè®¾å¤‡: {default_output['name']}")
            return default_output['index']
        except Exception as e:
            logger.error(f"è·å–é»˜è®¤è¾“å‡ºè®¾å¤‡å¤±è´¥: {e}")
            return None

    def calculate_rms(self, audio_data):
        """è®¡ç®—éŸ³é¢‘æ•°æ®çš„RMSï¼ˆå‡æ–¹æ ¹ï¼‰å€¼"""
        try:
            audio_array = np.frombuffer(audio_data, dtype=np.int16)
            # é¿å…ç©ºæ•°ç»„æˆ–å…¨é›¶æ•°ç»„å¯¼è‡´çš„é—®é¢˜
            if len(audio_array) == 0:
                return 0
            # è®¡ç®—RMSï¼Œä½¿ç”¨float64é¿å…æº¢å‡º
            rms = np.sqrt(np.mean(audio_array.astype(np.float64) ** 2))
            # å¤„ç†NaNæƒ…å†µ
            if np.isnan(rms):
                return 0
            return rms
        except Exception as e:
            logger.error(f"è®¡ç®—RMSå¤±è´¥: {e}")
            return 0

    def resample_audio(self, input_file, target_rate=16000):
        """
        é‡é‡‡æ ·éŸ³é¢‘æ–‡ä»¶åˆ°ç›®æ ‡é‡‡æ ·ç‡

        Args:
            input_file: è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            target_rate: ç›®æ ‡é‡‡æ ·ç‡,é»˜è®¤16000Hz (ASRæœåŠ¡è¦æ±‚)

        Returns:
            é‡é‡‡æ ·åçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        """
        # å¦‚æœå½“å‰é‡‡æ ·ç‡å°±æ˜¯ç›®æ ‡é‡‡æ ·ç‡,ç›´æ¥è¿”å›
        if self.RATE == target_rate:
            return input_file

        try:
            # è¯»å–åŸå§‹éŸ³é¢‘
            with wave.open(input_file, 'rb') as wf:
                n_channels = wf.getnchannels()
                sampwidth = wf.getsampwidth()
                framerate = wf.getframerate()
                frames = wf.readframes(wf.getnframes())

            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            audio_data = np.frombuffer(frames, dtype=np.int16)

            # è®¡ç®—é‡é‡‡æ ·æ¯”ä¾‹
            num_samples = int(len(audio_data) * target_rate / framerate)

            # ä½¿ç”¨scipyè¿›è¡Œé‡é‡‡æ ·
            resampled_data = signal.resample(audio_data, num_samples)
            resampled_data = resampled_data.astype(np.int16)

            # ä¿å­˜é‡é‡‡æ ·åçš„éŸ³é¢‘
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:
                output_file = f.name

            with wave.open(output_file, 'wb') as wf:
                wf.setnchannels(n_channels)
                wf.setsampwidth(sampwidth)
                wf.setframerate(target_rate)
                wf.writeframes(resampled_data.tobytes())

            # ä¸åˆ é™¤åŸå§‹æ–‡ä»¶ï¼Œç”±è°ƒç”¨è€…å†³å®šæ˜¯å¦åˆ é™¤

            return output_file

        except Exception as e:
            logger.error(f"éŸ³é¢‘é‡é‡‡æ ·å¤±è´¥: {e}")
            return input_file

    def check_wake_word(self, text):
        """
        æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«å”¤é†’è¯

        Args:
            text: è¯†åˆ«çš„æ–‡æœ¬

        Returns:
            tuple: (æ˜¯å¦åŒ…å«å”¤é†’è¯, å»é™¤å”¤é†’è¯åçš„æ–‡æœ¬)
        """
        if not text:
            return False, text

        text_lower = text.lower()

        for wake_word in self.WAKE_WORDS:
            if wake_word.lower() in text_lower:
                # æ‰¾åˆ°å”¤é†’è¯ï¼Œå»é™¤å®ƒ
                remaining_text = text.replace(wake_word, "").strip()
                logger.info(f"âœ… æ£€æµ‹åˆ°å”¤é†’è¯: {wake_word}")
                return True, remaining_text

        return False, text

    def record_audio_with_vad(self, input_device=None, for_wake_word=False, custom_timeout=None):
        """
        ä½¿ç”¨VADå½•éŸ³
        è‡ªåŠ¨æ£€æµ‹è¯´è¯å¼€å§‹å’Œç»“æŸ

        Args:
            input_device: è¾“å…¥è®¾å¤‡ç´¢å¼•
            for_wake_word: æ˜¯å¦ç”¨äºå”¤é†’è¯æ£€æµ‹ï¼ˆå”¤é†’è¯å½•éŸ³æ—¶é—´æ›´çŸ­ï¼‰
            custom_timeout: è‡ªå®šä¹‰è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œå¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨é»˜è®¤å€¼
        """
        global assistant_running

        if for_wake_word:
            logger.info("ğŸ” ç›‘å¬å”¤é†’è¯...")
            max_duration = 3  # å”¤é†’è¯æœ€é•¿3ç§’
        elif custom_timeout is not None:
            logger.info(f"ğŸ¤ å‡†å¤‡å½•éŸ³ï¼Œè¯·å¼€å§‹è¯´è¯...ï¼ˆæœ€é•¿{custom_timeout}ç§’ï¼‰")
            max_duration = custom_timeout
        else:
            logger.info("ğŸ¤ å‡†å¤‡å½•éŸ³ï¼Œè¯·å¼€å§‹è¯´è¯...")
            max_duration = 30  # æ­£å¸¸å¯¹è¯æœ€é•¿30ç§’

        stream = self.audio.open(
            format=self.FORMAT,
            channels=self.CHANNELS,
            rate=self.RATE,
            input=True,
            input_device_index=input_device,
            frames_per_buffer=self.CHUNK
        )

        frames = []
        silent_chunks = 0
        started = False
        max_silent_chunks = int(self.SILENCE_DURATION * self.RATE / self.CHUNK)

        # è®°å½•ä¸€äº›å…³é”®ä¿¡æ¯ç”¨äºè°ƒè¯•
        if not for_wake_word:
            logger.info(f"ğŸ“Š VADå‚æ•°: é™éŸ³é˜ˆå€¼={self.SILENCE_THRESHOLD}, é™éŸ³æ—¶é•¿={self.SILENCE_DURATION}ç§’, éœ€è¦é™éŸ³å¸§æ•°={max_silent_chunks}")

        # ç”¨äºè°ƒè¯•çš„è®¡æ•°å™¨
        debug_counter = 0
        rms_values = []  # è®°å½•æœ€è¿‘çš„RMSå€¼ç”¨äºè°ƒè¯•

        try:
            while assistant_running:  # æ£€æŸ¥è¿è¡Œæ ‡å¿—
                data = stream.read(self.CHUNK, exception_on_overflow=False)
                frames.append(data)

                # è®¡ç®—éŸ³é‡
                rms = self.calculate_rms(data)

                # æ¯éš”ä¸€å®šå¸§æ•°è¾“å‡ºè°ƒè¯•ä¿¡æ¯ï¼ˆé¿å…æ—¥å¿—è¿‡å¤šï¼‰
                debug_counter += 1
                rms_values.append(rms)
                if not for_wake_word and debug_counter % 20 == 0:  # æ¯20å¸§ï¼ˆçº¦0.5ç§’ï¼‰è¾“å‡ºä¸€æ¬¡
                    avg_rms = np.mean(rms_values[-20:]) if rms_values else 0
                    logger.debug(f"éŸ³é‡ç›‘æµ‹ - å½“å‰RMS: {int(rms)}, å¹³å‡RMS: {int(avg_rms)}, é˜ˆå€¼: {self.SILENCE_THRESHOLD}, å·²å½•åˆ¶: {len(frames)}å¸§")

                if rms > self.SILENCE_THRESHOLD:
                    if not started:
                        logger.info(f"ğŸ—£ï¸ æ£€æµ‹åˆ°è¯­éŸ³ï¼Œå¼€å§‹å½•éŸ³... (RMS: {int(rms)} > é˜ˆå€¼: {self.SILENCE_THRESHOLD})")
                        started = True
                    silent_chunks = 0
                else:
                    if started:
                        silent_chunks += 1
                        # æ¯éš”ä¸€å®šå¸§æ•°è¾“å‡ºé™éŸ³è®¡æ•°ï¼ˆæ”¹ä¸ºINFOçº§åˆ«ï¼Œæ›´é¢‘ç¹ï¼‰
                        if not for_wake_word and silent_chunks % 5 == 0:
                            logger.info(f"ğŸ”‡ é™éŸ³è®¡æ•°: {silent_chunks}/{max_silent_chunks} å¸§ (RMS: {int(rms)}, å·²å½•åˆ¶: {len(frames)}å¸§, æ—¶é•¿: {len(frames)*self.CHUNK/self.RATE:.1f}ç§’)")

                # æ£€æµ‹åˆ°è¶³å¤Ÿé•¿çš„é™éŸ³ï¼Œåœæ­¢å½•éŸ³
                if started and silent_chunks > max_silent_chunks:
                    if not for_wake_word:
                        logger.info(f"âœ… æ£€æµ‹åˆ°é™éŸ³ï¼Œå½•éŸ³ç»“æŸ (é™éŸ³æŒç»­: {silent_chunks}å¸§ = {silent_chunks*self.CHUNK/self.RATE:.2f}ç§’)")
                    break

                # é˜²æ­¢æ— é™å½•éŸ³
                if len(frames) > self.RATE / self.CHUNK * max_duration:
                    if not for_wake_word:
                        logger.warning("âš ï¸ å½•éŸ³è¶…æ—¶ï¼Œè‡ªåŠ¨åœæ­¢")
                    break

        finally:
            stream.stop_stream()
            stream.close()

        # å¦‚æœè¢«ä¸­æ–­åœæ­¢ï¼Œè¿”å›None
        if not assistant_running:
            return None

        # æ£€æŸ¥å½•éŸ³é•¿åº¦
        audio_duration = len(frames) * self.CHUNK / self.RATE
        if audio_duration < self.MIN_AUDIO_LENGTH:
            if not for_wake_word:
                logger.warning("âš ï¸ å½•éŸ³æ—¶é—´è¿‡çŸ­ï¼Œå¿½ç•¥")
            return None

        if not for_wake_word:
            logger.info(f"ğŸ“ å½•éŸ³å®Œæˆï¼Œæ—¶é•¿: {audio_duration:.2f} ç§’, æ€»å¸§æ•°: {len(frames)}")

        # ä¿å­˜ä¸ºä¸´æ—¶WAVæ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:
            temp_path = f.name

        wf = wave.open(temp_path, 'wb')
        wf.setnchannels(self.CHANNELS)
        wf.setsampwidth(self.audio.get_sample_size(self.FORMAT))
        wf.setframerate(self.RATE)
        wf.writeframes(b''.join(frames))
        wf.close()

        return temp_path

    def speech_to_text(self, audio_file):
        """è°ƒç”¨ASRæœåŠ¡è¿›è¡Œè¯­éŸ³è¯†åˆ«"""
        resampled_file = None
        try:
            # é‡é‡‡æ ·åˆ°16000Hz (ASRæœåŠ¡è¦æ±‚)
            resampled_file = self.resample_audio(audio_file, target_rate=16000)

            url = f"http://localhost:{self.ports['asr']}/transcribe"

            with open(resampled_file, 'rb') as f:
                files = {'audio': f}
                response = requests.post(url, files=files, timeout=30)

            if response.status_code == 200:
                result = response.json()
                text = result.get('text', '')
                logger.info(f"ğŸ—£ï¸ è¯†åˆ«ç»“æœ: {text}")
                return text
            else:
                logger.error(f"ASRè¯†åˆ«å¤±è´¥: {response.text}")
                return None

        except Exception as e:
            logger.error(f"ASRæœåŠ¡è°ƒç”¨å¤±è´¥: {e}")
            return None
        finally:
            # æ¸…ç†é‡é‡‡æ ·åçš„ä¸´æ—¶æ–‡ä»¶
            if resampled_file and os.path.exists(resampled_file):
                try:
                    os.unlink(resampled_file)
                except:
                    pass

    def chat(self, message):
        """è°ƒç”¨LLMæœåŠ¡è¿›è¡Œå¯¹è¯"""
        try:
            url = f"http://localhost:{self.ports['llm']}/chat"

            payload = {
                "message": message,
                "history": self.conversation_history
            }

            response = requests.post(url, json=payload, timeout=60)

            if response.status_code == 200:
                result = response.json()
                reply = result.get('message', '')

                # æ›´æ–°å¯¹è¯å†å² - ä½¿ç”¨äºŒç»´åˆ—è¡¨æ ¼å¼
                self.conversation_history.append([message, reply])

                # è‡ªåŠ¨æå–å¹¶å­˜å‚¨è®°å¿†
                if self.MEMORY_ENABLE and self.auto_extract and self.memory_client:
                    self._extract_and_store_memory(message, reply)

                logger.info(f"ğŸ¤– AIå›å¤: {reply}")
                return reply
            else:
                logger.error(f"LLMå¯¹è¯å¤±è´¥: {response.text}")
                return "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ã€‚"

        except Exception as e:
            logger.error(f"LLMæœåŠ¡è°ƒç”¨å¤±è´¥: {e}")
            return "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ã€‚"

    def text_to_speech(self, text):
        """è°ƒç”¨TTSæœåŠ¡è¿›è¡Œè¯­éŸ³åˆæˆ"""
        try:
            url = f"http://localhost:{self.ports['tts']}/synthesize"

            payload = {"text": text}
            timeout = max(60, len(text) // 10 + 30)

            response = requests.post(url, json=payload, timeout=timeout)

            if response.status_code == 200:
                # ä¿å­˜PCMéŸ³é¢‘
                with tempfile.NamedTemporaryFile(suffix='.pcm', delete=False) as f:
                    f.write(response.content)
                    return f.name
            else:
                logger.error(f"TTSåˆæˆå¤±è´¥: {response.text}")
                return None

        except Exception as e:
            logger.error(f"TTSæœåŠ¡è°ƒç”¨å¤±è´¥: {e}")
            return None

    def warmup_tts(self):
        """
        é¢„çƒ­TTSæœåŠ¡
        åœ¨ASRè¯†åˆ«æœŸé—´åå°é¢„çƒ­ï¼Œå‡å°‘é¦–å¥TTSå»¶è¿Ÿ
        """
        try:
            url = f"http://localhost:{self.ports['tts']}/synthesize/stream"
            payload = {"text": "å—¯", "stream": True}

            # ä½¿ç”¨çŸ­è¶…æ—¶ï¼Œå¿«é€Ÿé¢„çƒ­
            response = requests.post(url, json=payload, stream=True, timeout=5)

            if response.status_code == 200:
                # åªè¯»å–å°‘é‡æ•°æ®å°±ç»“æŸï¼Œä¸éœ€è¦å®Œæ•´æ¥æ”¶
                for _ in response.iter_content(chunk_size=4096):
                    break
                logger.debug("ğŸ”¥ TTSé¢„çƒ­å®Œæˆ")
            else:
                logger.debug(f"TTSé¢„çƒ­å¤±è´¥: {response.status_code}")
        except Exception as e:
            logger.debug(f"TTSé¢„çƒ­å¼‚å¸¸(å¿½ç•¥): {e}")


    def chat_stream(self, message, output_device=None):
        """
        æµå¼å¯¹è¯ï¼šLLMæµå¼è¾“å‡º + TTSå¼‚æ­¥ç”Ÿæˆå’Œæ’­æ”¾
        ä½¿ç”¨é˜Ÿåˆ—å®ç°ï¼šæ’­æ”¾ä¸€å¥è¯çš„åŒæ—¶ç”Ÿæˆä¸‹ä¸€å¥è¯

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            output_device: è¾“å‡ºè®¾å¤‡ç´¢å¼•
        """
        try:
            # è·å–æƒ…ç»ªä¸Šä¸‹æ–‡
            self.update_emotion_context()

            # è·å–è®°å¿†ä¸Šä¸‹æ–‡
            memory_context = ""
            if self.MEMORY_ENABLE and self.memory_client:
                memory_context = self.memory_client.get_context(message)
                if memory_context:
                    logger.info(f"ğŸ’­ æ‰¾åˆ°ç›¸å…³è®°å¿†: {len(memory_context)} å­—ç¬¦")

            # ç»„åˆæ‰€æœ‰ä¸Šä¸‹æ–‡
            context_parts = []
            if self.emotion_context:
                context_parts.append(self.emotion_context)
            if memory_context:
                context_parts.append(memory_context)

            # å¦‚æœæœ‰ä¸Šä¸‹æ–‡ï¼Œå°†å…¶æ·»åŠ åˆ°æ¶ˆæ¯ä¸­
            if context_parts:
                all_context = "ã€‚".join(context_parts)
                enhanced_message = f"{all_context}ã€‚{message}"
                logger.info(f"ğŸ­ æ¶ˆæ¯å·²æ·»åŠ ä¸Šä¸‹æ–‡")
            else:
                enhanced_message = message

            url = f"http://localhost:{self.ports['llm']}/chat/stream"

            payload = {
                "message": enhanced_message,
                "history": self.conversation_history
            }

            # ä½¿ç”¨æµå¼è¯·æ±‚
            response = requests.post(url, json=payload, stream=True, timeout=120)

            if response.status_code != 200:
                logger.error(f"LLMæµå¼å¯¹è¯å¤±è´¥: {response.text}")
                return

            # åˆ›å»ºæ’­æ”¾é˜Ÿåˆ—
            playback_queue = AudioPlaybackQueue(self)
            playback_queue.start(output_device)

            # é‡ç½®æ‰“æ–­æ ‡å¿—
            self.interrupt_flag = False

            # å¯åŠ¨æ‰“æ–­ç›‘å¬çº¿ç¨‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.INTERRUPT_MODE:
                self.interrupt_monitor_thread = threading.Thread(
                    target=self.monitor_interrupt,
                    args=(self.input_device,),
                    daemon=True
                )
                self.interrupt_monitor_thread.start()
                logger.info("ğŸ‘‚ æ‰“æ–­ç›‘å¬çº¿ç¨‹å·²å¯åŠ¨")

            full_reply = ""
            text_buffer = ""
            sentence_delimiters = ["ã€‚", "ï¼", "?", "!", "?", "\n", ".", ";"]

            logger.info("ğŸ¤– AIå¼€å§‹å›å¤...")

            try:
                # é€å—æ¥æ”¶LLMè¾“å‡º
                for line in response.iter_lines():
                    # æ£€æŸ¥æ˜¯å¦è¢«æ‰“æ–­
                    if self.interrupt_flag:
                        logger.info("â¹ï¸ æ£€æµ‹åˆ°æ‰“æ–­ï¼Œåœæ­¢ç”Ÿæˆå†…å®¹")
                        break

                    if not line:
                        continue

                    try:
                        # è§£æSSEæ ¼å¼
                        line = line.decode('utf-8')
                        if line.startswith('data: '):
                            data = line[6:]  # å»æ‰ 'data: ' å‰ç¼€

                            if data == '[DONE]':
                                break

                            import json
                            chunk_data = json.loads(data)
                            chunk = chunk_data.get('delta', '')

                            if chunk:
                                text_buffer += chunk
                                full_reply += chunk

                                # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„å¥å­
                                for delimiter in sentence_delimiters:
                                    if delimiter in text_buffer:
                                        # æ‰¾åˆ°å¥å­ç»“æŸç¬¦ï¼Œåˆ†å‰²å¥å­
                                        sentences = text_buffer.split(delimiter)
                                        for i in range(len(sentences) - 1):
                                            sentence = sentences[i] + delimiter
                                            if sentence.strip():
                                                logger.info(f"ğŸ“ ç”Ÿæˆæ–‡æœ¬ç‰‡æ®µ: {sentence[:50]}...")

                                                # å¼‚æ­¥ç”ŸæˆTTSéŸ³é¢‘
                                                pcm_file = self.text_to_speech(sentence)
                                                if pcm_file:
                                                    # åŠ å…¥æ’­æ”¾é˜Ÿåˆ—ï¼ˆä¸ç­‰å¾…æ’­æ”¾å®Œæˆï¼‰
                                                    playback_queue.add(pcm_file, sentence)
                                                    logger.debug(f"âœ… TTSå·²ç”Ÿæˆå¹¶åŠ å…¥é˜Ÿåˆ—ï¼Œé˜Ÿåˆ—é•¿åº¦: {playback_queue.get_queue_size()}")

                                        # ä¿ç•™æœ€åä¸€ä¸ªæœªå®Œæˆçš„éƒ¨åˆ†
                                        text_buffer = sentences[-1]
                                        break

                    except Exception as e:
                        logger.error(f"å¤„ç†æµå¼æ•°æ®å‡ºé”™: {e}")
                        continue

                # å¤„ç†å‰©ä½™çš„æ–‡æœ¬ï¼ˆå¦‚æœæ²¡æœ‰è¢«æ‰“æ–­ï¼‰
                if text_buffer.strip() and not self.interrupt_flag:
                    logger.info(f"ğŸ“ ç”Ÿæˆæœ€åç‰‡æ®µ: {text_buffer[:50]}...")
                    pcm_file = self.text_to_speech(text_buffer)
                    if pcm_file:
                        playback_queue.add(pcm_file, text_buffer)

                # ç­‰å¾…æ‰€æœ‰éŸ³é¢‘æ’­æ”¾å®Œæˆï¼ˆæˆ–è¢«æ‰“æ–­ï¼‰
                if not self.interrupt_flag:
                    logger.info(f"â³ ç­‰å¾…æ‰€æœ‰éŸ³é¢‘æ’­æ”¾å®Œæˆ... (é˜Ÿåˆ—å‰©ä½™: {playback_queue.get_queue_size()})")
                    playback_queue.wait_until_done()
                    logger.info("âœ… æ‰€æœ‰éŸ³é¢‘æ’­æ”¾å®Œæˆ")
                else:
                    logger.info("â¹ï¸ å¯¹è¯å·²è¢«æ‰“æ–­")
                    # æ’­æ”¾æ‰“æ–­ç¡®è®¤éŸ³é¢‘ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
                    if self.INTERRUPT_MODE and self.INTERRUPT_REPLY:
                        try:
                            self.quick_reply(self.INTERRUPT_REPLY, output_device)
                        except Exception as e:
                            logger.error(f"æ’­æ”¾æ‰“æ–­ç¡®è®¤éŸ³é¢‘å¤±è´¥: {e}")

            finally:
                # åœæ­¢æ‰“æ–­ç›‘å¬
                self.interrupt_flag = True  # ç¡®ä¿ç›‘å¬çº¿ç¨‹åœæ­¢

                # åœæ­¢æ’­æ”¾é˜Ÿåˆ—
                playback_queue.stop()

            # æ›´æ–°å¯¹è¯å†å² - ä½¿ç”¨äºŒç»´åˆ—è¡¨æ ¼å¼
            if full_reply and not self.interrupt_flag:  # åªæœ‰åœ¨æœ‰å›å¤ä¸”æœªè¢«æ‰“æ–­æ—¶æ‰æ·»åŠ åˆ°å†å²
                self.conversation_history.append([message, full_reply])

            logger.info(f"âœ… å®Œæ•´å›å¤: {full_reply[:100]}..." if len(full_reply) > 100 else f"âœ… å®Œæ•´å›å¤: {full_reply}")

        except Exception as e:
            logger.error(f"æµå¼å¯¹è¯å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def monitor_interrupt(self, input_device=None):
        """
        ç›‘å¬æ‰“æ–­è¯çš„åå°çº¿ç¨‹ï¼ˆç®€åŒ–ç‰ˆï¼‰
        åœ¨AIæ’­æ”¾æ—¶æŒç»­ç›‘å¬ç”¨æˆ·æ˜¯å¦è¯´è¯ï¼ˆåŸºäºéŸ³é‡æ£€æµ‹ï¼‰
        å½“æ£€æµ‹åˆ°è¯´è¯æ—¶ï¼Œè¿›è¡ŒASRè¯†åˆ«æ£€æŸ¥æ˜¯å¦ä¸ºæ‰“æ–­è¯
        """
        if not self.INTERRUPT_MODE:
            return

        logger.info("ğŸ‘‚ å¼€å§‹ç›‘å¬æ‰“æ–­ï¼ˆéŸ³é‡æ£€æµ‹æ¨¡å¼ï¼‰...")

        try:
            # ä½¿ç”¨ç‹¬ç«‹çš„PyAudioå®ä¾‹é¿å…å†²çª
            with suppress_stderr():
                monitor_audio = pyaudio.PyAudio()

            # æ‰“å¼€éŸ³é¢‘æµï¼ˆæŒç»­ç›‘å¬ï¼‰
            stream = monitor_audio.open(
                format=self.FORMAT,
                channels=self.CHANNELS,
                rate=self.RATE,
                input=True,
                input_device_index=input_device,
                frames_per_buffer=self.CHUNK
            )

            logger.info("ğŸ‘‚ æ‰“æ–­ç›‘å¬éŸ³é¢‘æµå·²æ‰“å¼€")
            silent_threshold = self.SILENCE_THRESHOLD * 2  # éœ€è¦æ¯”é™éŸ³é˜ˆå€¼é«˜ï¼Œæ‰è®¤ä¸ºæ˜¯è¯´è¯

            while not self.interrupt_flag:
                try:
                    # è¯»å–éŸ³é¢‘æ•°æ®
                    data = stream.read(self.CHUNK, exception_on_overflow=False)

                    # è®¡ç®—RMS
                    audio_array = np.frombuffer(data, dtype=np.int16)
                    if len(audio_array) > 0:
                        rms = int(np.sqrt(np.mean(audio_array.astype(np.float64) ** 2)))

                        # æ£€æµ‹åˆ°è¯´è¯ï¼ˆRMSè¶…è¿‡é˜ˆå€¼ï¼‰
                        if rms > silent_threshold:
                            logger.debug(f"ğŸ‘‚ æ£€æµ‹åˆ°å£°éŸ³ï¼ŒRMS: {rms} > {silent_threshold}")

                            # å½•åˆ¶å®Œæ•´çš„è¯ï¼ˆç”¨äºASRè¯†åˆ«ï¼‰
                            # æš‚æ—¶å…³é—­æµ
                            stream.stop_stream()
                            stream.close()

                            # å½•åˆ¶ä¸€æ®µéŸ³é¢‘ç”¨äºè¯†åˆ«
                            logger.debug("ğŸ¤ å½•åˆ¶éŸ³é¢‘è¿›è¡Œæ‰“æ–­è¯è¯†åˆ«...")
                            frames = [data]  # åŒ…å«åˆšæ‰æ£€æµ‹åˆ°çš„æ•°æ®

                            # ç»§ç»­å½•åˆ¶1ç§’
                            temp_stream = monitor_audio.open(
                                format=self.FORMAT,
                                channels=self.CHANNELS,
                                rate=self.RATE,
                                input=True,
                                input_device_index=input_device,
                                frames_per_buffer=self.CHUNK
                            )

                            for _ in range(int(self.RATE / self.CHUNK * 1.0)):  # 1ç§’
                                data = temp_stream.read(self.CHUNK, exception_on_overflow=False)
                                frames.append(data)

                            temp_stream.stop_stream()
                            temp_stream.close()

                            # ä¿å­˜éŸ³é¢‘å¹¶è¯†åˆ«
                            temp_file = f"/tmp/interrupt_detect_{int(time.time() * 1000)}.wav"
                            wf = wave.open(temp_file, 'wb')
                            wf.setnchannels(self.CHANNELS)
                            wf.setsampwidth(monitor_audio.get_sample_size(self.FORMAT))
                            wf.setframerate(self.RATE)
                            wf.writeframes(b''.join(frames))
                            wf.close()

                            # ASRè¯†åˆ«
                            text = self.speech_to_text(temp_file)

                            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                            try:
                                os.unlink(temp_file)
                            except:
                                pass

                            if text:
                                logger.debug(f"ğŸ‘‚ ç›‘å¬åˆ°: {text}")

                                # æ£€æŸ¥æ˜¯å¦åŒ…å«æ‰“æ–­è¯
                                for interrupt_word in self.INTERRUPT_WORDS:
                                    if interrupt_word in text:
                                        logger.info(f"ğŸ›‘ æ£€æµ‹åˆ°æ‰“æ–­è¯: {interrupt_word}")
                                        self.interrupt_flag = True
                                        monitor_audio.terminate()
                                        return

                            # é‡æ–°æ‰“å¼€æµç»§ç»­ç›‘å¬
                            if not self.interrupt_flag:
                                stream = monitor_audio.open(
                                    format=self.FORMAT,
                                    channels=self.CHANNELS,
                                    rate=self.RATE,
                                    input=True,
                                    input_device_index=input_device,
                                    frames_per_buffer=self.CHUNK
                                )

                except Exception as e:
                    logger.error(f"ç›‘å¬å¾ªç¯å‡ºé”™: {e}")
                    break

            # æ¸…ç†èµ„æº
            try:
                stream.stop_stream()
                stream.close()
            except:
                pass

            monitor_audio.terminate()
            logger.info("ğŸ‘‚ æ‰“æ–­ç›‘å¬å·²åœæ­¢")

        except Exception as e:
            logger.error(f"æ‰“æ–­ç›‘å¬å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def monitor_wake_word(self, input_device=None):
        """
        å®æ—¶è¿ç»­ç›‘å¬å”¤é†’è¯
        ç±»ä¼¼äºæ‰“æ–­è¯ç›‘å¬ï¼ŒæŒç»­å½•éŸ³å¹¶è¯†åˆ«æ˜¯å¦åŒ…å«å”¤é†’è¯

        Args:
            input_device: è¾“å…¥è®¾å¤‡ç´¢å¼•

        Returns:
            tuple: (has_wake_word, remaining_text) æ˜¯å¦æ£€æµ‹åˆ°å”¤é†’è¯å’Œå‰©ä½™æ–‡æœ¬
        """
        try:
            logger.info("ğŸ‘‚ å¼€å§‹è¿ç»­ç›‘å¬å”¤é†’è¯...")

            # åˆ›å»ºç‹¬ç«‹çš„PyAudioå®ä¾‹ç”¨äºç›‘å¬
            with suppress_stderr():
                monitor_audio = pyaudio.PyAudio()

            stream = monitor_audio.open(
                format=self.FORMAT,
                channels=self.CHANNELS,
                rate=self.RATE,
                input=True,
                input_device_index=input_device,
                frames_per_buffer=self.CHUNK
            )

            logger.info("ğŸ‘‚ å”¤é†’è¯ç›‘å¬éŸ³é¢‘æµå·²æ‰“å¼€")

            frames = []
            is_speaking = False
            silent_chunks = 0
            # ä½¿ç”¨é…ç½®çš„é™éŸ³æŒç»­æ—¶é—´,ç”¨äºå”¤é†’è¯æ£€æµ‹
            max_silent_chunks = int(self.RATE / self.CHUNK * self.SILENCE_DURATION)
            chunk_counter = 0  # ç”¨äºå®šæœŸè¾“å‡ºçŠ¶æ€

            silent_threshold = self.SILENCE_THRESHOLD * 0.8  # å”¤é†’è¯æ£€æµ‹ä½¿ç”¨è¾ƒä½é˜ˆå€¼,æ›´çµæ•

            while assistant_running and not self.interrupt_flag:
                try:
                    # è¯»å–éŸ³é¢‘æ•°æ®
                    data = stream.read(self.CHUNK, exception_on_overflow=False)
                    frames.append(data)
                    chunk_counter += 1

                    # è®¡ç®—éŸ³é‡(RMS) - ä½¿ç”¨ç›¸åŒçš„æ–¹æ³•
                    rms = self.calculate_rms(data)

                    # æ¯50å¸§(çº¦1ç§’)è¾“å‡ºä¸€æ¬¡çŠ¶æ€
                    if chunk_counter % 50 == 0:
                        logger.info(f"ğŸ¤ ç›‘å¬ä¸­... RMS={int(rms)}, é˜ˆå€¼={int(silent_threshold)}, è¯´è¯={is_speaking}, é™éŸ³å¸§={silent_chunks}")

                    # æ£€æµ‹æ˜¯å¦åœ¨è¯´è¯
                    if rms > silent_threshold:
                        if not is_speaking:
                            logger.info(f"ğŸ—£ï¸ æ£€æµ‹åˆ°è¯´è¯å¼€å§‹ (RMS={int(rms)} > {int(silent_threshold)})")
                        is_speaking = True
                        silent_chunks = 0
                    elif is_speaking:
                        silent_chunks += 1
                        if silent_chunks % 10 == 0:  # æ¯10å¸§è¾“å‡ºä¸€æ¬¡
                            logger.info(f"ğŸ”‡ é™éŸ³è®¡æ•°: {silent_chunks}/{max_silent_chunks}")

                    # å¦‚æœè¯´è¯åé™éŸ³è¶…è¿‡é˜ˆå€¼ï¼Œè¿›è¡Œè¯†åˆ«
                    if is_speaking and silent_chunks >= max_silent_chunks:
                        logger.info(f"ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³ç»“æŸï¼Œå¼€å§‹è¯†åˆ«... (ç´¯è®¡ {len(frames)} å¸§, çº¦{len(frames)*self.CHUNK/self.RATE:.1f}ç§’)")

                        # æš‚åœæµ
                        stream.stop_stream()
                        stream.close()

                        # ä¿å­˜éŸ³é¢‘å¹¶è¯†åˆ«
                        if len(frames) > 0:
                            temp_file = f"/tmp/wake_monitor_{int(time.time() * 1000)}.wav"
                            wf = wave.open(temp_file, 'wb')
                            wf.setnchannels(self.CHANNELS)
                            wf.setsampwidth(monitor_audio.get_sample_size(self.FORMAT))
                            wf.setframerate(self.RATE)
                            wf.writeframes(b''.join(frames))
                            wf.close()

                            # ASRè¯†åˆ«
                            text = self.speech_to_text(temp_file)

                            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                            try:
                                os.unlink(temp_file)
                            except:
                                pass

                            if text:
                                logger.info(f"ğŸ‘‚ ç›‘å¬åˆ°: {text}")

                                # æ£€æŸ¥æ˜¯å¦åŒ…å«å”¤é†’è¯
                                has_wake_word, remaining_text = self.check_wake_word(text)

                                if has_wake_word:
                                    logger.info(f"ğŸ¯ æ£€æµ‹åˆ°å”¤é†’è¯! å‰©ä½™æ–‡æœ¬: {remaining_text}")
                                    # æ¸…ç†èµ„æº
                                    monitor_audio.terminate()
                                    return True, remaining_text
                                else:
                                    logger.info(f"âŒ æœªæ£€æµ‹åˆ°å”¤é†’è¯ï¼Œç»§ç»­ç›‘å¬...")
                            else:
                                logger.info(f"âš ï¸ è¯†åˆ«ç»“æœä¸ºç©ºï¼Œç»§ç»­ç›‘å¬...")

                        # é‡ç½®çŠ¶æ€ï¼Œç»§ç»­ç›‘å¬
                        frames = []
                        is_speaking = False
                        silent_chunks = 0

                        # é‡æ–°æ‰“å¼€æµç»§ç»­ç›‘å¬
                        if assistant_running and not self.interrupt_flag:
                            stream = monitor_audio.open(
                                format=self.FORMAT,
                                channels=self.CHANNELS,
                                rate=self.RATE,
                                input=True,
                                input_device_index=input_device,
                                frames_per_buffer=self.CHUNK
                            )

                    # é™åˆ¶ç¼“å†²åŒºå¤§å°ï¼Œé¿å…æ— é™ç´¯ç§¯ï¼ˆæœ€å¤šä¿ç•™5ç§’ï¼‰
                    max_frames = int(self.RATE / self.CHUNK * 5)
                    if len(frames) > max_frames:
                        frames = frames[-max_frames:]

                except Exception as e:
                    logger.error(f"ç›‘å¬å¾ªç¯å‡ºé”™: {e}")
                    break

            # æ¸…ç†èµ„æº
            try:
                stream.stop_stream()
                stream.close()
            except:
                pass

            monitor_audio.terminate()
            logger.info("ğŸ‘‚ å”¤é†’è¯ç›‘å¬å·²åœæ­¢")
            return False, ""

        except Exception as e:
            logger.error(f"å”¤é†’è¯ç›‘å¬å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            return False, ""

    def record_audio_short(self, input_device=None, duration=2.0):
        """
        å½•åˆ¶çŸ­éŸ³é¢‘ï¼ˆç”¨äºæ‰“æ–­è¯æ£€æµ‹ï¼‰
        ä¸ä½¿ç”¨VADï¼Œç›´æ¥å½•åˆ¶æŒ‡å®šæ—¶é•¿

        Args:
            input_device: è¾“å…¥è®¾å¤‡ç´¢å¼•
            duration: å½•åˆ¶æ—¶é•¿ï¼ˆç§’ï¼‰

        Returns:
            str: å½•åˆ¶çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        """
        try:
            stream = self.audio.open(
                format=self.FORMAT,
                channels=self.CHANNELS,
                rate=self.RATE,
                input=True,
                input_device_index=input_device,
                frames_per_buffer=self.CHUNK
            )

            frames = []
            num_chunks = int(self.RATE / self.CHUNK * duration)

            for _ in range(num_chunks):
                data = stream.read(self.CHUNK, exception_on_overflow=False)
                frames.append(data)

            stream.stop_stream()
            stream.close()

            # ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
            temp_file = f"/tmp/interrupt_detect_{int(time.time() * 1000)}.wav"
            wf = wave.open(temp_file, 'wb')
            wf.setnchannels(self.CHANNELS)
            wf.setsampwidth(self.audio.get_sample_size(self.FORMAT))
            wf.setframerate(self.RATE)
            wf.writeframes(b''.join(frames))
            wf.close()

            return temp_file

        except Exception as e:
            logger.error(f"çŸ­éŸ³é¢‘å½•åˆ¶å¤±è´¥: {e}")
            return None

    def quick_reply(self, text, output_device=None, use_cache=True):
        """
        å¿«é€Ÿå“åº”ï¼šç›´æ¥åˆæˆå¹¶æ’­æ”¾æŒ‡å®šæ–‡æœ¬ï¼ˆæ”¯æŒç¼“å­˜ï¼‰

        Args:
            text: è¦æ’­æ”¾çš„æ–‡æœ¬
            output_device: è¾“å‡ºè®¾å¤‡ç´¢å¼•
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜ï¼ˆé»˜è®¤Trueï¼‰
        """
        try:
            logger.info(f"ğŸ’¬ å¿«é€Ÿå›å¤: {text}")

            pcm_file = None
            cache_type = None
            should_cleanup = True  # æ˜¯å¦éœ€è¦æ¸…ç†ä¸´æ—¶æ–‡ä»¶

            # åˆ¤æ–­æ˜¯å”¤é†’å›å¤ã€æ‰“æ–­å›å¤è¿˜æ˜¯æ€è€ƒå›å¤ï¼Œä»¥ä½¿ç”¨å¯¹åº”çš„ç¼“å­˜
            if use_cache:
                if text == self.WAKE_REPLY and self.wake_reply_audio_cache:
                    # æ£€æŸ¥ç¼“å­˜æ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨
                    if os.path.exists(self.wake_reply_audio_cache):
                        pcm_file = self.wake_reply_audio_cache
                        should_cleanup = False
                        logger.info(f"ğŸµ ä½¿ç”¨å”¤é†’å›å¤éŸ³é¢‘ç¼“å­˜")
                    else:
                        logger.warning(f"âš ï¸ å”¤é†’å›å¤ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨ï¼Œé‡æ–°ç”Ÿæˆ")
                        self.wake_reply_audio_cache = None
                elif text == self.INTERRUPT_REPLY and self.interrupt_reply_audio_cache:
                    # æ£€æŸ¥ç¼“å­˜æ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨
                    if os.path.exists(self.interrupt_reply_audio_cache):
                        pcm_file = self.interrupt_reply_audio_cache
                        should_cleanup = False
                        logger.info(f"ğŸµ ä½¿ç”¨æ‰“æ–­å›å¤éŸ³é¢‘ç¼“å­˜")
                    else:
                        logger.warning(f"âš ï¸ æ‰“æ–­å›å¤ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨ï¼Œé‡æ–°ç”Ÿæˆ")
                        self.interrupt_reply_audio_cache = None
                elif text == self.THINKING_REPLY and self.thinking_reply_audio_cache:
                    # æ£€æŸ¥ç¼“å­˜æ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨
                    if os.path.exists(self.thinking_reply_audio_cache):
                        pcm_file = self.thinking_reply_audio_cache
                        should_cleanup = False
                        logger.info(f"ğŸµ ä½¿ç”¨æ€è€ƒå›å¤éŸ³é¢‘ç¼“å­˜")
                    else:
                        logger.warning(f"âš ï¸ æ€è€ƒå›å¤ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨ï¼Œé‡æ–°ç”Ÿæˆ")
                        self.thinking_reply_audio_cache = None

            # å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œåˆ™ç”Ÿæˆæ–°çš„éŸ³é¢‘
            if not pcm_file:
                # å¯¹å”¤é†’ã€æ€è€ƒã€æ‰“æ–­å›å¤æ·»åŠ "ä¸€"å‰ç¼€
                tts_text = text
                cache_key = text  # ç”¨äºç¼“å­˜æ–‡ä»¶åçš„key
                if text in [self.WAKE_REPLY, self.THINKING_REPLY, self.INTERRUPT_REPLY]:
                    tts_text = "ä¸€" + text
                    cache_key = tts_text  # ä½¿ç”¨å¸¦å‰ç¼€çš„æ–‡æœ¬ä½œä¸ºç¼“å­˜key
                    logger.debug(f"ğŸ”¤ æ·»åŠ å‰ç¼€: {tts_text}")

                pcm_file = self.text_to_speech(tts_text)
                if not pcm_file:
                    logger.error("TTSç”Ÿæˆå¤±è´¥")
                    return

                # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆä½¿ç”¨å¸¦å‰ç¼€çš„æ–‡æœ¬ä½œä¸ºkeyï¼‰
                if use_cache:
                    if text == self.WAKE_REPLY:
                        cache_type = 'wake'
                        cached_file = self._save_audio_cache(cache_key, cache_type, pcm_file)
                        if cached_file:
                            self.wake_reply_audio_cache = cached_file
                    elif text == self.INTERRUPT_REPLY:
                        cache_type = 'interrupt'
                        cached_file = self._save_audio_cache(cache_key, cache_type, pcm_file)
                        if cached_file:
                            self.interrupt_reply_audio_cache = cached_file
                    elif text == self.THINKING_REPLY:
                        cache_type = 'thinking'
                        cached_file = self._save_audio_cache(cache_key, cache_type, pcm_file)
                        if cached_file:
                            self.thinking_reply_audio_cache = cached_file

            # æ’­æ”¾éŸ³é¢‘
            if pcm_file:
                self.play_audio(pcm_file, output_device)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆç¼“å­˜æ–‡ä»¶ä¸æ¸…ç†ï¼‰
                if should_cleanup:
                    try:
                        os.unlink(pcm_file)
                    except:
                        pass

        except Exception as e:
            logger.error(f"å¿«é€Ÿå›å¤å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def play_audio(self, pcm_file, output_device=None):
        """
        æ’­æ”¾PCMéŸ³é¢‘åˆ°æŒ‡å®šè¾“å‡ºè®¾å¤‡ï¼ˆè“ç‰™éŸ³ç®±ï¼‰
        ä¼˜å…ˆä½¿ç”¨paplayï¼ˆPulseAudioï¼‰ç¡®ä¿è“ç‰™å…¼å®¹æ€§
        """
        try:
            logger.info("ğŸ”Š å¼€å§‹æ’­æ”¾éŸ³é¢‘...")

            # PCMå‚æ•°ï¼ˆä¸TTSæœåŠ¡ä¸€è‡´ï¼‰
            RATE = 22050
            CHANNELS = 1
            FORMAT = pyaudio.paInt16

            # æ–¹æ³•1: ä¼˜å…ˆä½¿ç”¨paplay (PulseAudio) - å¯¹è“ç‰™æ”¯æŒæœ€å¥½
            try:
                # å°†PCMè½¬æ¢ä¸ºWAVæ ¼å¼ï¼ˆpaplayéœ€è¦WAVæ ¼å¼ï¼‰
                wav_file = pcm_file.replace('.pcm', '.wav')

                # è¯»å–PCMæ•°æ®
                with open(pcm_file, 'rb') as f:
                    pcm_data = f.read()

                # åº”ç”¨éŸ³é‡è°ƒæ•´
                if self.OUTPUT_VOLUME < 100:
                    # å°†PCMæ•°æ®è½¬æ¢ä¸ºnumpyæ•°ç»„
                    audio_array = np.frombuffer(pcm_data, dtype=np.int16)
                    # åº”ç”¨éŸ³é‡ï¼ˆ0-100% å¯¹åº” 0.0-1.0ï¼‰
                    volume_factor = self.OUTPUT_VOLUME / 100.0
                    audio_array = (audio_array * volume_factor).astype(np.int16)
                    pcm_data = audio_array.tobytes()
                    logger.info(f"åº”ç”¨éŸ³é‡è°ƒæ•´: {self.OUTPUT_VOLUME}%")

                # å†™å…¥WAVæ–‡ä»¶
                import wave
                with wave.open(wav_file, 'wb') as wf:
                    wf.setnchannels(CHANNELS)
                    wf.setsampwidth(2)  # 16-bit = 2 bytes
                    wf.setframerate(RATE)
                    wf.writeframes(pcm_data)

                # ä½¿ç”¨paplayæ’­æ”¾ï¼ˆä¼šè‡ªåŠ¨ä½¿ç”¨ç³»ç»Ÿé»˜è®¤è¾“å‡ºè®¾å¤‡ï¼ŒåŒ…æ‹¬è“ç‰™éŸ³ç®±ï¼‰
                paplay_cmd = ['paplay', wav_file]

                # å¦‚æœæŒ‡å®šäº†è¾“å‡ºè®¾å¤‡ï¼Œéœ€è¦æŸ¥æ‰¾å¯¹åº”çš„PulseAudio sinkåç§°
                if output_device is not None:
                    try:
                        # è·å–PyAudioè®¾å¤‡ä¿¡æ¯
                        device_info = self.audio.get_device_info_by_index(output_device)
                        device_name = device_info['name']

                        # æŸ¥æ‰¾å¯¹åº”çš„PulseAudio sink
                        # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨é»˜è®¤sinkï¼Œå› ä¸ºå·²ç»é€šè¿‡Webç•Œé¢è®¾ç½®äº†
                        logger.info(f"ç›®æ ‡è¾“å‡ºè®¾å¤‡: {device_name}")

                    except Exception as e:
                        logger.warning(f"æ— æ³•è·å–è®¾å¤‡ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤è¾“å‡º: {e}")

                # æ‰§è¡Œæ’­æ”¾
                result = subprocess.run(
                    paplay_cmd,
                    capture_output=True,
                    timeout=30
                )

                if result.returncode == 0:
                    logger.info("âœ… éŸ³é¢‘æ’­æ”¾å®Œæˆ (ä½¿ç”¨paplay)")
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    os.unlink(pcm_file)
                    os.unlink(wav_file)
                    return
                else:
                    logger.warning(f"paplayæ’­æ”¾å¤±è´¥: {result.stderr.decode('utf-8', errors='ignore')}")
                    # ç»§ç»­å°è¯•PyAudioæ–¹å¼

            except FileNotFoundError:
                logger.warning("æœªæ‰¾åˆ°paplayå‘½ä»¤ï¼Œå°è¯•ä½¿ç”¨PyAudioæ’­æ”¾")
            except Exception as e:
                logger.warning(f"paplayæ’­æ”¾å‡ºé”™: {e}ï¼Œå°è¯•ä½¿ç”¨PyAudioæ’­æ”¾")

            # æ–¹æ³•2: ä½¿ç”¨PyAudioæ’­æ”¾ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
            logger.info("ä½¿ç”¨PyAudioæ’­æ”¾éŸ³é¢‘...")

            # è¯»å–PCMæ•°æ®
            with open(pcm_file, 'rb') as f:
                pcm_data = f.read()

            # åº”ç”¨éŸ³é‡è°ƒæ•´
            if self.OUTPUT_VOLUME < 100:
                audio_array = np.frombuffer(pcm_data, dtype=np.int16)
                volume_factor = self.OUTPUT_VOLUME / 100.0
                audio_array = (audio_array * volume_factor).astype(np.int16)
                pcm_data = audio_array.tobytes()
                logger.info(f"åº”ç”¨éŸ³é‡è°ƒæ•´: {self.OUTPUT_VOLUME}%")

            # æ‰“å¼€éŸ³é¢‘æµ
            stream = self.audio.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=RATE,
                output=True,
                output_device_index=output_device,
                frames_per_buffer=1024
            )

            # æ’­æ”¾éŸ³é¢‘
            stream.write(pcm_data)

            # å…³é—­æµ
            stream.stop_stream()
            stream.close()

            logger.info("âœ… éŸ³é¢‘æ’­æ”¾å®Œæˆ (ä½¿ç”¨PyAudio)")

            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            os.unlink(pcm_file)

        except Exception as e:
            logger.error(f"éŸ³é¢‘æ’­æ”¾å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())

    def _extract_and_store_memory(self, user_message: str, ai_response: str):
        """
        æå–å¹¶å­˜å‚¨å¯¹è¯è®°å¿†

        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            ai_response: AIå›å¤
        """
        try:
            # è°ƒç”¨è®°å¿†æœåŠ¡è‡ªåŠ¨æå–è®°å¿†
            extracted = self.memory_client.auto_extract(user_message, ai_response)

            if extracted:
                total_extracted = sum(extracted.values())
                logger.info(f"ğŸ§  è®°å¿†æå–: åå¥½={extracted.get('preferences_found', 0)}, "
                          f"äº‹å®={extracted.get('facts_found', 0)}, "
                          f"äº‹ä»¶={extracted.get('events_found', 0)}")

                # å¦‚æœæå–åˆ°äº†é‡è¦ä¿¡æ¯ï¼Œè®°å½•æ›´è¯¦ç»†çš„ä¿¡æ¯
                if total_extracted > 0:
                    logger.debug(f"ğŸ“ å¯¹è¯è®°å¿†å·²å­˜å‚¨: ç”¨æˆ·='{user_message[:50]}...' "
                               f"åŠ©æ‰‹='{ai_response[:50]}...'")

        except Exception as e:
            logger.error(f"è®°å¿†æå–å¤±è´¥: {e}")
            # ä¸å½±å“å¯¹è¯æµç¨‹ï¼Œé™é»˜å¤„ç†é”™è¯¯

    def run(self, input_device=None, output_device=None):
        """
        è¿è¡Œè¯­éŸ³å¯¹è¯å¾ªç¯

        Args:
            input_device: è¾“å…¥è®¾å¤‡ç´¢å¼•ï¼ˆUSBéº¦å…‹é£ï¼‰ï¼ŒNoneä½¿ç”¨é»˜è®¤
            output_device: è¾“å‡ºè®¾å¤‡ç´¢å¼•ï¼ˆè“ç‰™éŸ³ç®±ï¼‰ï¼ŒNoneä½¿ç”¨é»˜è®¤
        """
        global assistant_running

        logger.info("=" * 60)
        logger.info("ğŸ¤– çº¿ä¸‹è¯­éŸ³å¯¹è¯ç³»ç»Ÿå¯åŠ¨")
        logger.info("=" * 60)

        # æ˜¾ç¤ºè®¾å¤‡ä¿¡æ¯
        if input_device is None:
            input_device = self.get_default_input_device()
        if output_device is None:
            output_device = self.get_default_output_device()

        logger.info(f"ä½¿ç”¨è¾“å…¥è®¾å¤‡: {input_device}")
        logger.info(f"ä½¿ç”¨è¾“å‡ºè®¾å¤‡: {output_device}")
        logger.info("æŒ‰ Ctrl+C é€€å‡ºç¨‹åº")
        logger.info("=" * 60)

        try:
            while assistant_running:  # æ”¹ä¸ºæ£€æŸ¥assistant_runningæ ‡å¿—
                # å”¤é†’è¯æ¨¡å¼
                if self.WAKE_MODE:
                    # é‡ç½®æ‰“æ–­æ ‡å¿—(å”¤é†’è¯ç›‘å¬é˜¶æ®µä¸åº”è¯¥è¢«æ‰“æ–­)
                    self.interrupt_flag = False

                    # 1. å®æ—¶è¿ç»­ç›‘å¬å”¤é†’è¯ï¼ˆç±»ä¼¼æ‰“æ–­è¯çš„å®ç°ï¼‰
                    has_wake_word, remaining_text = self.monitor_wake_word(input_device)

                    if not has_wake_word:
                        # æ²¡æœ‰æ£€æµ‹åˆ°å”¤é†’è¯æˆ–è€…è¢«ä¸­æ–­ï¼Œç»§ç»­ä¸‹ä¸€è½®
                        continue

                    logger.info("ğŸ¯ å·²å”¤é†’ï¼")

                    # 2. ç«‹å³æ’­æ”¾ç¡®è®¤è¯­éŸ³
                    self.quick_reply(self.WAKE_REPLY, output_device)

                    # 3. æ£€æŸ¥å”¤é†’è¯åé¢æ˜¯å¦æœ‰å†…å®¹
                    prefix_text = ""
                    if remaining_text and remaining_text.strip():
                        # å”¤é†’è¯åé¢å·²ç»æœ‰éƒ¨åˆ†å†…å®¹ï¼Œä¿å­˜èµ·æ¥
                        prefix_text = remaining_text.strip()
                        logger.info(f"ğŸ“Œ æ£€æµ‹åˆ°å‰ç¼€å†…å®¹: {prefix_text}")

                    # 4. é‡æ–°å½•éŸ³ç­‰å¾…å®Œæ•´é—®é¢˜ï¼ˆä½¿ç”¨å®Œæ•´çš„é™éŸ³æ£€æµ‹æ—¶é•¿ï¼‰
                    logger.info("ğŸ’¬ è¯·è¯´å‡ºæ‚¨çš„é—®é¢˜...")
                    dialogue_audio = self.record_audio_with_vad(input_device, for_wake_word=False)

                    if dialogue_audio is None:
                        # å¦‚æœæ²¡æœ‰å½•åˆ°æ–°å†…å®¹ï¼Œä½†æœ‰å‰ç¼€å†…å®¹ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨
                        if prefix_text:
                            user_text = prefix_text
                            logger.info(f"ğŸ“ ä½¿ç”¨å‰ç¼€å†…å®¹ä½œä¸ºé—®é¢˜: {user_text}")
                        else:
                            logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œé‡æ–°ç›‘å¬å”¤é†’è¯")
                            continue
                    else:
                        # 5. è¯†åˆ«æ–°å½•éŸ³çš„å†…å®¹
                        new_text = self.speech_to_text(dialogue_audio)
                        os.unlink(dialogue_audio)

                        if not new_text or not new_text.strip():
                            # æ–°å½•éŸ³ä¸ºç©ºï¼Œä½¿ç”¨å‰ç¼€å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
                            if prefix_text:
                                user_text = prefix_text
                                logger.info(f"ğŸ“ æ–°å½•éŸ³ä¸ºç©ºï¼Œä½¿ç”¨å‰ç¼€å†…å®¹: {user_text}")
                            else:
                                logger.warning("âš ï¸ è¯†åˆ«ç»“æœä¸ºç©ºï¼Œé‡æ–°ç›‘å¬å”¤é†’è¯")
                                continue
                        else:
                            # 6. åˆå¹¶å‰ç¼€å†…å®¹å’Œæ–°å†…å®¹
                            if prefix_text:
                                # æœ‰å‰ç¼€å†…å®¹ï¼Œæ‹¼æ¥èµ·æ¥
                                user_text = f"{prefix_text}ï¼Œ{new_text.strip()}"
                                logger.info(f"ğŸ”— åˆå¹¶å†…å®¹: å‰ç¼€'{prefix_text}' + æ–°å†…å®¹'{new_text.strip()}' = '{user_text}'")
                            else:
                                # æ²¡æœ‰å‰ç¼€å†…å®¹ï¼Œç›´æ¥ä½¿ç”¨æ–°å†…å®¹
                                user_text = new_text.strip()

                    logger.info(f"ğŸ“ å®Œæ•´é—®é¢˜: {user_text}")

                    # 7. æ’­æ”¾æ€è€ƒç¡®è®¤è¯­éŸ³çš„åŒæ—¶ï¼Œåå°é¢„çƒ­TTS
                    warmup_thread = threading.Thread(target=self.warmup_tts, daemon=True)
                    warmup_thread.start()

                    self.quick_reply(self.THINKING_REPLY, output_device)

                    # 8. ä½¿ç”¨æµå¼å¯¹è¯ï¼šLLMæµå¼è¾“å‡º + TTSæµå¼æ’­æ”¾
                    self.chat_stream(user_text, output_device)

                    # 9. å¯¹è¯å®Œæˆåï¼Œè¿›å…¥è¿ç»­å¯¹è¯æ¨¡å¼ï¼ˆç­‰å¾…ç”¨æˆ·ç»§ç»­æé—®ï¼Œæ— éœ€å†æ¬¡å”¤é†’ï¼‰
                    while True:
                        logger.info(f"ğŸ’¬ ç­‰å¾…ç»§ç»­å¯¹è¯ï¼ˆ{self.CONTINUE_DIALOGUE_TIMEOUT}ç§’å†…æ— è¯­éŸ³å°†è¿”å›å¾…æœºï¼‰...")

                        # å°è¯•å½•éŸ³ï¼Œä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´
                        continue_audio = self.record_audio_with_vad(
                            input_device,
                            for_wake_word=False,
                            custom_timeout=self.CONTINUE_DIALOGUE_TIMEOUT
                        )

                        if continue_audio is None:
                            # æ²¡æœ‰å½•åˆ°éŸ³é¢‘ï¼Œè¿”å›å¾…æœºæ¨¡å¼
                            logger.info("â¸ï¸ æœªæ£€æµ‹åˆ°ç»§ç»­å¯¹è¯ï¼Œè¿”å›å¾…æœºæ¨¡å¼")
                            break

                        # è¯†åˆ«æ–°çš„é—®é¢˜
                        continue_text = self.speech_to_text(continue_audio)
                        os.unlink(continue_audio)

                        if not continue_text or not continue_text.strip():
                            logger.info("â¸ï¸ è¯†åˆ«ç»“æœä¸ºç©ºï¼Œè¿”å›å¾…æœºæ¨¡å¼")
                            break

                        logger.info(f"ğŸ“ ç»§ç»­å¯¹è¯: {continue_text}")

                        # æ’­æ”¾æ€è€ƒç¡®è®¤è¯­éŸ³çš„åŒæ—¶ï¼Œåå°é¢„çƒ­TTS
                        warmup_thread = threading.Thread(target=self.warmup_tts, daemon=True)
                        warmup_thread.start()

                        self.quick_reply(self.THINKING_REPLY, output_device)

                        # ç»§ç»­å¯¹è¯
                        self.chat_stream(continue_text, output_device)

                else:
                    # éå”¤é†’è¯æ¨¡å¼ï¼Œç›´æ¥å½•éŸ³
                    audio_file = self.record_audio_with_vad(input_device)

                    if audio_file is None:
                        continue

                    # è¯­éŸ³è¯†åˆ«
                    user_text = self.speech_to_text(audio_file)
                    os.unlink(audio_file)

                    if not user_text or not user_text.strip():
                        logger.warning("âš ï¸ è¯†åˆ«ç»“æœä¸ºç©ºï¼Œè¯·é‡è¯•")
                        continue

                    logger.info(f"ğŸ“ ç”¨æˆ·é—®é¢˜: {user_text}")

                    # æ’­æ”¾æ€è€ƒç¡®è®¤è¯­éŸ³çš„åŒæ—¶ï¼Œåå°é¢„çƒ­TTS
                    warmup_thread = threading.Thread(target=self.warmup_tts, daemon=True)
                    warmup_thread.start()

                    self.quick_reply(self.THINKING_REPLY, output_device)

                    # ä½¿ç”¨æµå¼å¯¹è¯ï¼šLLMæµå¼è¾“å‡º + TTSæµå¼æ’­æ”¾
                    self.chat_stream(user_text, output_device)

                logger.info("-" * 60)
                if self.WAKE_MODE:
                    logger.info("ğŸ’¤ å¯¹è¯ç»“æŸï¼Œç­‰å¾…ä¸‹æ¬¡å”¤é†’...")
                    logger.info("-" * 60)

        except KeyboardInterrupt:
            logger.info("\nğŸ‘‹ ç”¨æˆ·é€€å‡ºï¼Œå†è§ï¼")
        finally:
            # ä¸å†è°ƒç”¨terminate()ï¼Œè®©PyAudioå¯¹è±¡ä¿æŒå¯ç”¨
            # è¿™æ ·å¯ä»¥é‡å¤å¯åŠ¨/åœæ­¢è¯­éŸ³å¯¹è¯
            logger.info("ğŸ›‘ è¯­éŸ³å¯¹è¯å¾ªç¯å·²é€€å‡º")


# å…¨å±€è¯­éŸ³åŠ©æ‰‹å®ä¾‹
assistant = None
assistant_thread = None
assistant_running = False


@app.get("/devices")
async def get_audio_devices():
    """è·å–æ‰€æœ‰éŸ³é¢‘è®¾å¤‡åˆ—è¡¨"""
    try:
        with suppress_stderr():
            audio = pyaudio.PyAudio()
            devices = []

            for i in range(audio.get_device_count()):
                info = audio.get_device_info_by_index(i)
                devices.append({
                    "index": i,
                    "name": info['name'],
                    "max_input_channels": info['maxInputChannels'],
                    "max_output_channels": info['maxOutputChannels'],
                    "default_sample_rate": info['defaultSampleRate']
                })

            audio.terminate()

        return {
            "success": True,
            "devices": devices
        }
    except Exception as e:
        logger.error(f"è·å–éŸ³é¢‘è®¾å¤‡åˆ—è¡¨å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }


@app.post("/start")
async def start_voice_chat():
    """å¯åŠ¨è¯­éŸ³å¯¹è¯"""
    global assistant, assistant_thread, assistant_running

    try:
        # æ£€æŸ¥æ˜¯å¦å·²å¯ç”¨
        voice_config = get_config('voice_chat')
        if not voice_config.get('enable', False):
            return {
                "success": False,
                "message": "è¯­éŸ³å¯¹è¯æœªå¯ç”¨ï¼Œè¯·åœ¨é…ç½®ä¸­å¯ç”¨"
            }

        # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨è¿è¡Œ
        if assistant_running:
            return {
                "success": False,
                "message": "è¯­éŸ³å¯¹è¯å·²ç»åœ¨è¿è¡Œä¸­"
            }

        # åˆ›å»ºåŠ©æ‰‹å®ä¾‹
        assistant = VoiceAssistant()

        # è·å–è®¾å¤‡é…ç½®
        input_device = voice_config.get('input_device')
        output_device = voice_config.get('output_device')

        # åœ¨åå°çº¿ç¨‹è¿è¡Œ
        def run_assistant():
            global assistant_running
            assistant_running = True
            try:
                assistant.run(input_device=input_device, output_device=output_device)
            except Exception as e:
                logger.error(f"è¯­éŸ³å¯¹è¯è¿è¡Œå‡ºé”™: {e}")
            finally:
                assistant_running = False

        assistant_thread = threading.Thread(target=run_assistant, daemon=True)
        assistant_thread.start()

        return {
            "success": True,
            "message": "è¯­éŸ³å¯¹è¯å·²å¯åŠ¨"
        }
    except Exception as e:
        logger.error(f"å¯åŠ¨è¯­éŸ³å¯¹è¯å¤±è´¥: {e}")
        assistant_running = False
        return {
            "success": False,
            "error": str(e)
        }


@app.post("/stop")
async def stop_voice_chat():
    """åœæ­¢è¯­éŸ³å¯¹è¯"""
    global assistant, assistant_running

    try:
        if not assistant_running:
            return {
                "success": False,
                "message": "è¯­éŸ³å¯¹è¯æœªåœ¨è¿è¡Œ"
            }

        # åªè®¾ç½®æ ‡å¿—ä½ä¸ºFalseï¼Œè®©runå‡½æ•°è‡ªç„¶é€€å‡º
        # ä¸è¦è°ƒç”¨terminate()ï¼Œå› ä¸ºè¿™ä¼šä½¿PyAudioå¯¹è±¡å¤±æ•ˆ
        assistant_running = False

        return {
            "success": True,
            "message": "è¯­éŸ³å¯¹è¯å·²åœæ­¢"
        }
    except Exception as e:
        logger.error(f"åœæ­¢è¯­éŸ³å¯¹è¯å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }


@app.get("/status")
async def get_status():
    """è·å–è¯­éŸ³å¯¹è¯çŠ¶æ€"""
    return {
        "running": assistant_running,
        "enabled": get_config('voice_chat').get('enable', False)
    }


@app.post("/reload_config")
async def reload_config_endpoint():
    """
    é‡æ–°åŠ è½½é…ç½®
    å¦‚æœè¯­éŸ³å¯¹è¯æ­£åœ¨è¿è¡Œï¼Œä¼šçƒ­æ›´æ–°é…ç½®å‚æ•°
    å¦‚æœæœªè¿è¡Œï¼Œåªé‡æ–°åŠ è½½é…ç½®æ–‡ä»¶
    """
    global assistant

    try:
        if assistant and assistant_running:
            # è¯­éŸ³å¯¹è¯æ­£åœ¨è¿è¡Œï¼Œè°ƒç”¨å®ä¾‹çš„ reload_config æ–¹æ³•
            result = assistant.reload_config()
            return result
        else:
            # è¯­éŸ³å¯¹è¯æœªè¿è¡Œï¼Œåªé‡æ–°åŠ è½½é…ç½®æ–‡ä»¶
            from config_loader import reload_config
            reload_config()
            return {
                "success": True,
                "message": "é…ç½®æ–‡ä»¶å·²é‡æ–°åŠ è½½ï¼ˆè¯­éŸ³å¯¹è¯æœªè¿è¡Œï¼‰"
            }
    except Exception as e:
        logger.error(f"é…ç½®é‡æ–°åŠ è½½å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return {
            "success": False,
            "error": str(e)
        }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return {
        "status": "healthy",
        "service": "voice_chat",
        "running": assistant_running,
        "enabled": get_config('voice_chat').get('enable', False)
    }


# å…¨å±€å˜é‡ç”¨äºéŸ³é‡ç›‘æµ‹
volume_monitor_running = False
volume_monitor_thread = None
latest_volume_data = {
    "current_rms": 0,
    "min_rms": 99999,
    "max_rms": 0,
    "avg_rms": 0,
    "samples": [],
    "recommended_threshold": 0
}


def calculate_recommended_threshold(samples, percentile=80):
    """
    åŸºäºæ ·æœ¬æ•°æ®è®¡ç®—æ¨èçš„é™éŸ³é˜ˆå€¼

    Args:
        samples: RMSæ ·æœ¬åˆ—è¡¨
        percentile: ç™¾åˆ†ä½æ•°ï¼ˆé»˜è®¤80%ï¼Œå³é«˜äº80%çš„ç¯å¢ƒå™ªéŸ³ï¼‰

    Returns:
        æ¨èçš„é˜ˆå€¼
    """
    if not samples or len(samples) < 5:
        return 0

    sorted_samples = sorted(samples)
    index = int(len(sorted_samples) * percentile / 100)
    base_threshold = sorted_samples[index]

    # æ·»åŠ 30%çš„å®‰å…¨è¾¹é™…ï¼Œç¡®ä¿èƒ½å¤Ÿæ£€æµ‹åˆ°è¯´è¯
    recommended = int(base_threshold * 1.3)

    return recommended


def volume_monitor_worker(input_device=None, duration=10):
    """
    åå°çº¿ç¨‹ï¼šç›‘æµ‹éº¦å…‹é£éŸ³é‡

    Args:
        input_device: è¾“å…¥è®¾å¤‡ç´¢å¼•
        duration: ç›‘æµ‹æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
    """
    global volume_monitor_running, latest_volume_data

    try:
        logger.info(f"ğŸ¤ å¼€å§‹éŸ³é‡ç›‘æµ‹ï¼ŒæŒç»­ {duration} ç§’...")

        # é‡ç½®æ•°æ®
        latest_volume_data = {
            "current_rms": 0,
            "min_rms": 99999,
            "max_rms": 0,
            "avg_rms": 0,
            "samples": [],
            "recommended_threshold": 0
        }

        with suppress_stderr():
            audio = pyaudio.PyAudio()

        CHUNK = 1024
        FORMAT = pyaudio.paInt16
        CHANNELS = 1

        # è·å–è®¾å¤‡ä¿¡æ¯ï¼Œæ£€æµ‹æ”¯æŒçš„é‡‡æ ·ç‡
        if input_device is not None:
            device_info = audio.get_device_info_by_index(input_device)
        else:
            device_info = audio.get_default_input_device_info()

        # å°è¯•å¤šä¸ªå¸¸ç”¨é‡‡æ ·ç‡ï¼Œæ‰¾åˆ°è®¾å¤‡æ”¯æŒçš„
        supported_rates = [16000, 44100, 48000, 22050, 8000]
        RATE = None

        for rate in supported_rates:
            try:
                # æµ‹è¯•æ˜¯å¦æ”¯æŒè¯¥é‡‡æ ·ç‡
                with suppress_stderr():
                    test_stream = audio.open(
                        format=FORMAT,
                        channels=CHANNELS,
                        rate=rate,
                        input=True,
                        input_device_index=input_device,
                        frames_per_buffer=CHUNK
                    )
                    test_stream.close()
                RATE = rate
                logger.info(f"âœ… ä½¿ç”¨é‡‡æ ·ç‡: {RATE} Hz")
                break
            except Exception:
                continue

        if RATE is None:
            # å¦‚æœéƒ½ä¸æ”¯æŒï¼Œä½¿ç”¨è®¾å¤‡é»˜è®¤é‡‡æ ·ç‡
            RATE = int(device_info.get('defaultSampleRate', 44100))
            logger.warning(f"âš ï¸ ä½¿ç”¨è®¾å¤‡é»˜è®¤é‡‡æ ·ç‡: {RATE} Hz")

        # æ‰“å¼€éŸ³é¢‘æµ
        stream = audio.open(
            format=FORMAT,
            channels=CHANNELS,
            rate=RATE,
            input=True,
            input_device_index=input_device,
            frames_per_buffer=CHUNK
        )

        start_time = time.time()
        sample_count = 0

        while volume_monitor_running and (time.time() - start_time) < duration:
            # è¯»å–éŸ³é¢‘æ•°æ®
            audio_data = stream.read(CHUNK, exception_on_overflow=False)

            # è®¡ç®—RMS
            audio_array = np.frombuffer(audio_data, dtype=np.int16)
            if len(audio_array) > 0:
                rms = np.sqrt(np.mean(audio_array.astype(np.float64) ** 2))
                if not np.isnan(rms):
                    rms = int(rms)

                    # æ›´æ–°ç»Ÿè®¡æ•°æ®
                    latest_volume_data["current_rms"] = rms
                    latest_volume_data["samples"].append(rms)

                    if rms < latest_volume_data["min_rms"]:
                        latest_volume_data["min_rms"] = rms
                    if rms > latest_volume_data["max_rms"]:
                        latest_volume_data["max_rms"] = rms

                    # æ¯10ä¸ªæ ·æœ¬è®¡ç®—ä¸€æ¬¡å¹³å‡å€¼å’Œæ¨èé˜ˆå€¼
                    sample_count += 1
                    if sample_count % 10 == 0:
                        latest_volume_data["avg_rms"] = int(np.mean(latest_volume_data["samples"]))
                        latest_volume_data["recommended_threshold"] = calculate_recommended_threshold(
                            latest_volume_data["samples"]
                        )

            time.sleep(0.05)  # 50msé—´éš”

        # æ¸…ç†
        stream.stop_stream()
        stream.close()
        audio.terminate()

        # æœ€ç»ˆè®¡ç®—
        if latest_volume_data["samples"]:
            latest_volume_data["avg_rms"] = int(np.mean(latest_volume_data["samples"]))
            latest_volume_data["recommended_threshold"] = calculate_recommended_threshold(
                latest_volume_data["samples"]
            )

        logger.info(f"âœ… éŸ³é‡ç›‘æµ‹å®Œæˆ")
        logger.info(f"  å¹³å‡RMS: {latest_volume_data['avg_rms']}")
        logger.info(f"  èŒƒå›´: {latest_volume_data['min_rms']} - {latest_volume_data['max_rms']}")
        logger.info(f"  æ¨èé˜ˆå€¼: {latest_volume_data['recommended_threshold']}")

    except Exception as e:
        logger.error(f"éŸ³é‡ç›‘æµ‹å¤±è´¥: {e}")
        import traceback
        logger.error(traceback.format_exc())
    finally:
        volume_monitor_running = False


@app.post("/volume/start")
async def start_volume_monitor(input_device: int = None, duration: int = 10):
    """
    å¼€å§‹ç›‘æµ‹éº¦å…‹é£éŸ³é‡

    Args:
        input_device: è¾“å…¥è®¾å¤‡ç´¢å¼•ï¼ˆnullä½¿ç”¨é»˜è®¤è®¾å¤‡ï¼‰
        duration: ç›‘æµ‹æŒç»­æ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤10ç§’ï¼‰
    """
    global volume_monitor_running, volume_monitor_thread

    try:
        if volume_monitor_running:
            return {
                "success": False,
                "message": "éŸ³é‡ç›‘æµ‹å·²åœ¨è¿è¡Œä¸­"
            }

        # è·å–é…ç½®çš„è¾“å…¥è®¾å¤‡
        if input_device is None:
            voice_config = get_config('voice_chat')
            input_device = voice_config.get('input_device')

        # å¯åŠ¨ç›‘æµ‹çº¿ç¨‹
        volume_monitor_running = True
        volume_monitor_thread = threading.Thread(
            target=volume_monitor_worker,
            args=(input_device, duration),
            daemon=True
        )
        volume_monitor_thread.start()

        return {
            "success": True,
            "message": f"éŸ³é‡ç›‘æµ‹å·²å¯åŠ¨ï¼ŒæŒç»­ {duration} ç§’",
            "duration": duration
        }

    except Exception as e:
        logger.error(f"å¯åŠ¨éŸ³é‡ç›‘æµ‹å¤±è´¥: {e}")
        volume_monitor_running = False
        return {
            "success": False,
            "error": str(e)
        }


@app.post("/volume/stop")
async def stop_volume_monitor():
    """åœæ­¢éŸ³é‡ç›‘æµ‹"""
    global volume_monitor_running

    try:
        if not volume_monitor_running:
            return {
                "success": False,
                "message": "éŸ³é‡ç›‘æµ‹æœªåœ¨è¿è¡Œ"
            }

        volume_monitor_running = False

        return {
            "success": True,
            "message": "éŸ³é‡ç›‘æµ‹å·²åœæ­¢"
        }

    except Exception as e:
        logger.error(f"åœæ­¢éŸ³é‡ç›‘æµ‹å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }


@app.get("/volume/data")
async def get_volume_data():
    """è·å–å½“å‰éŸ³é‡ç›‘æµ‹æ•°æ®"""
    global latest_volume_data, volume_monitor_running

    return {
        "success": True,
        "running": volume_monitor_running,
        "data": {
            "current_rms": latest_volume_data["current_rms"],
            "min_rms": latest_volume_data["min_rms"] if latest_volume_data["min_rms"] != 99999 else 0,
            "max_rms": latest_volume_data["max_rms"],
            "avg_rms": latest_volume_data["avg_rms"],
            "sample_count": len(latest_volume_data["samples"]),
            "recommended_threshold": latest_volume_data["recommended_threshold"]
        }
    }


def auto_start_voice_chat():
    """è‡ªåŠ¨å¯åŠ¨è¯­éŸ³å¯¹è¯ï¼ˆåœ¨åå°çº¿ç¨‹ä¸­è°ƒç”¨APIï¼‰"""
    import time
    # ç­‰å¾…APIæœåŠ¡å™¨å®Œå…¨å¯åŠ¨
    time.sleep(2)

    try:
        voice_config = get_config('voice_chat')
        if voice_config.get('enable', False):
            logger.info("ğŸ¤– é…ç½®å·²å¯ç”¨ï¼Œè‡ªåŠ¨å¯åŠ¨è¯­éŸ³å¯¹è¯...")
            # è°ƒç”¨å†…éƒ¨å¯åŠ¨å‡½æ•°
            import asyncio
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(start_voice_chat())
            if result.get('success'):
                logger.info("âœ… è¯­éŸ³å¯¹è¯å·²è‡ªåŠ¨å¯åŠ¨")
            else:
                logger.warning(f"âš ï¸ è‡ªåŠ¨å¯åŠ¨å¤±è´¥: {result.get('message', result.get('error'))}")
        else:
            logger.info("â„¹ï¸ è¯­éŸ³å¯¹è¯æœªå¯ç”¨ï¼Œä»…è¿è¡ŒAPIæœåŠ¡å™¨")
    except Exception as e:
        logger.error(f"è‡ªåŠ¨å¯åŠ¨è¯­éŸ³å¯¹è¯å¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•° - å¯åŠ¨APIæœåŠ¡å™¨"""
    # é»˜è®¤è¿è¡ŒAPIæœåŠ¡å™¨æ¨¡å¼
    port = get_config('services').get('voice_chat', 5004)
    logger.info(f"ğŸš€ å¯åŠ¨è¯­éŸ³å¯¹è¯APIæœåŠ¡å™¨ï¼Œç«¯å£: {port}")

    # åœ¨åå°çº¿ç¨‹å¯åŠ¨è‡ªåŠ¨å¯åŠ¨é€»è¾‘
    auto_start_thread = threading.Thread(target=auto_start_voice_chat, daemon=True)
    auto_start_thread.start()

    uvicorn.run(app, host="0.0.0.0", port=port, log_level="info")


def standalone_mode():
    """ç‹¬ç«‹è¿è¡Œæ¨¡å¼ï¼ˆç›´æ¥è¿è¡Œè¯­éŸ³å¯¹è¯ï¼Œä¸å¯åŠ¨APIæœåŠ¡å™¨ï¼‰"""
    assistant = VoiceAssistant()

    # åˆ—å‡ºæ‰€æœ‰éŸ³é¢‘è®¾å¤‡
    assistant.list_audio_devices()

    # è¿è¡Œå¯¹è¯ç³»ç»Ÿ
    # å¯ä»¥æ‰‹åŠ¨æŒ‡å®šè®¾å¤‡ç´¢å¼•ï¼Œä¾‹å¦‚ï¼š
    # assistant.run(input_device=1, output_device=2)
    assistant.run()


if __name__ == "__main__":
    main()
